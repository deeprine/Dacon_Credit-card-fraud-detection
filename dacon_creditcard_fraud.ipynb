{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tiM7jwnNvL5z"
   },
   "source": [
    "Import library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "N76GaNzFvS_7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.float_format = '{:.10f}'.format\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "\n",
    "from pylab import rcParams\n",
    "\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import os\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# GPU 0번\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "id": "qmbI81GxzzI1",
    "outputId": "027d98ce-cd1f-42f2-ded8-7da7c0944705"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.3583540616</td>\n",
       "      <td>-1.3401630747</td>\n",
       "      <td>1.7732093426</td>\n",
       "      <td>0.3797795930</td>\n",
       "      <td>-0.5031981333</td>\n",
       "      <td>1.8004993808</td>\n",
       "      <td>0.7914609565</td>\n",
       "      <td>0.2476757866</td>\n",
       "      <td>-1.5146543226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2479981535</td>\n",
       "      <td>0.7716794019</td>\n",
       "      <td>0.9094122623</td>\n",
       "      <td>-0.6892809565</td>\n",
       "      <td>-0.3276418337</td>\n",
       "      <td>-0.1390965715</td>\n",
       "      <td>-0.0553527940</td>\n",
       "      <td>-0.0597518406</td>\n",
       "      <td>4.9837210927</td>\n",
       "      <td>-0.9949717454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.9662717116</td>\n",
       "      <td>-0.1852260081</td>\n",
       "      <td>1.7929933396</td>\n",
       "      <td>-0.8632912750</td>\n",
       "      <td>-0.0103088796</td>\n",
       "      <td>1.2472031675</td>\n",
       "      <td>0.2376089398</td>\n",
       "      <td>0.3774358747</td>\n",
       "      <td>-1.3870240627</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1083004520</td>\n",
       "      <td>0.0052735968</td>\n",
       "      <td>-0.1903205187</td>\n",
       "      <td>-1.1755753319</td>\n",
       "      <td>0.6473760346</td>\n",
       "      <td>-0.2219288445</td>\n",
       "      <td>0.0627228487</td>\n",
       "      <td>0.0614576285</td>\n",
       "      <td>1.4182910641</td>\n",
       "      <td>-0.9949717454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.4259658844</td>\n",
       "      <td>0.9605230449</td>\n",
       "      <td>1.1411093423</td>\n",
       "      <td>-0.1682520798</td>\n",
       "      <td>0.4209868808</td>\n",
       "      <td>-0.0297275517</td>\n",
       "      <td>0.4762009487</td>\n",
       "      <td>0.2603143331</td>\n",
       "      <td>-0.5686713757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2082535147</td>\n",
       "      <td>-0.5598247963</td>\n",
       "      <td>-0.0263976680</td>\n",
       "      <td>-0.3714265832</td>\n",
       "      <td>-0.2327938167</td>\n",
       "      <td>0.1059147791</td>\n",
       "      <td>0.2538442247</td>\n",
       "      <td>0.0810802569</td>\n",
       "      <td>-0.2561307902</td>\n",
       "      <td>-0.9949599972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.6442694423</td>\n",
       "      <td>1.4179635455</td>\n",
       "      <td>1.0743803764</td>\n",
       "      <td>-0.4921990185</td>\n",
       "      <td>0.9489340948</td>\n",
       "      <td>0.4281184628</td>\n",
       "      <td>1.1206313584</td>\n",
       "      <td>-3.8078642387</td>\n",
       "      <td>0.6153747307</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9434653398</td>\n",
       "      <td>-1.0154547098</td>\n",
       "      <td>0.0575035299</td>\n",
       "      <td>-0.6497090056</td>\n",
       "      <td>-0.4152665662</td>\n",
       "      <td>-0.0516342969</td>\n",
       "      <td>-1.2069210809</td>\n",
       "      <td>-1.0853391883</td>\n",
       "      <td>0.2626982463</td>\n",
       "      <td>-0.9949012559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.8942860822</td>\n",
       "      <td>0.2861571963</td>\n",
       "      <td>-0.1131922127</td>\n",
       "      <td>-0.2715261301</td>\n",
       "      <td>2.6695986596</td>\n",
       "      <td>3.7218180611</td>\n",
       "      <td>0.3701451277</td>\n",
       "      <td>0.8510844432</td>\n",
       "      <td>-0.3920475868</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0734251001</td>\n",
       "      <td>-0.2680916322</td>\n",
       "      <td>-0.2042326699</td>\n",
       "      <td>1.0115918019</td>\n",
       "      <td>0.3732046801</td>\n",
       "      <td>-0.3841573077</td>\n",
       "      <td>0.0117473565</td>\n",
       "      <td>0.1424043299</td>\n",
       "      <td>0.9948997415</td>\n",
       "      <td>-0.9949012559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID            V1            V2            V3            V4            V5  \\\n",
       "0   3 -1.3583540616 -1.3401630747  1.7732093426  0.3797795930 -0.5031981333   \n",
       "1   4 -0.9662717116 -0.1852260081  1.7929933396 -0.8632912750 -0.0103088796   \n",
       "2   6 -0.4259658844  0.9605230449  1.1411093423 -0.1682520798  0.4209868808   \n",
       "3   8 -0.6442694423  1.4179635455  1.0743803764 -0.4921990185  0.9489340948   \n",
       "4   9 -0.8942860822  0.2861571963 -0.1131922127 -0.2715261301  2.6695986596   \n",
       "\n",
       "             V6           V7            V8            V9  ...           V21  \\\n",
       "0  1.8004993808 0.7914609565  0.2476757866 -1.5146543226  ...  0.2479981535   \n",
       "1  1.2472031675 0.2376089398  0.3774358747 -1.3870240627  ... -0.1083004520   \n",
       "2 -0.0297275517 0.4762009487  0.2603143331 -0.5686713757  ... -0.2082535147   \n",
       "3  0.4281184628 1.1206313584 -3.8078642387  0.6153747307  ...  1.9434653398   \n",
       "4  3.7218180611 0.3701451277  0.8510844432 -0.3920475868  ... -0.0734251001   \n",
       "\n",
       "            V22           V23           V24           V25           V26  \\\n",
       "0  0.7716794019  0.9094122623 -0.6892809565 -0.3276418337 -0.1390965715   \n",
       "1  0.0052735968 -0.1903205187 -1.1755753319  0.6473760346 -0.2219288445   \n",
       "2 -0.5598247963 -0.0263976680 -0.3714265832 -0.2327938167  0.1059147791   \n",
       "3 -1.0154547098  0.0575035299 -0.6497090056 -0.4152665662 -0.0516342969   \n",
       "4 -0.2680916322 -0.2042326699  1.0115918019  0.3732046801 -0.3841573077   \n",
       "\n",
       "            V27           V28           V29           V30  \n",
       "0 -0.0553527940 -0.0597518406  4.9837210927 -0.9949717454  \n",
       "1  0.0627228487  0.0614576285  1.4182910641 -0.9949717454  \n",
       "2  0.2538442247  0.0810802569 -0.2561307902 -0.9949599972  \n",
       "3 -1.2069210809 -1.0853391883  0.2626982463 -0.9949012559  \n",
       "4  0.0117473565  0.1424043299  0.9948997415 -0.9949012559  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ano/train.csv\")\n",
    "df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>113842.0000000000</td>\n",
       "      <td>113842.0000000000</td>\n",
       "      <td>113842.0000000000</td>\n",
       "      <td>113842.0000000000</td>\n",
       "      <td>113842.0000000000</td>\n",
       "      <td>113842.0000000000</td>\n",
       "      <td>113842.0000000000</td>\n",
       "      <td>113842.0000000000</td>\n",
       "      <td>113842.0000000000</td>\n",
       "      <td>113842.0000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>113842.0000000000</td>\n",
       "      <td>113842.0000000000</td>\n",
       "      <td>113842.0000000000</td>\n",
       "      <td>113842.0000000000</td>\n",
       "      <td>113842.0000000000</td>\n",
       "      <td>113842.0000000000</td>\n",
       "      <td>113842.0000000000</td>\n",
       "      <td>113842.0000000000</td>\n",
       "      <td>113842.0000000000</td>\n",
       "      <td>113842.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>142025.5278368265</td>\n",
       "      <td>0.0001972910</td>\n",
       "      <td>0.0012887948</td>\n",
       "      <td>0.0097173629</td>\n",
       "      <td>-0.0041692083</td>\n",
       "      <td>0.0004749962</td>\n",
       "      <td>0.0051411577</td>\n",
       "      <td>0.0057690239</td>\n",
       "      <td>-0.0024505883</td>\n",
       "      <td>-0.0021070687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0012424691</td>\n",
       "      <td>0.0000004088</td>\n",
       "      <td>-0.0013174176</td>\n",
       "      <td>-0.0008841494</td>\n",
       "      <td>0.0016801536</td>\n",
       "      <td>-0.0002933701</td>\n",
       "      <td>-0.0002337128</td>\n",
       "      <td>-0.0005080546</td>\n",
       "      <td>0.9272530175</td>\n",
       "      <td>0.1162315431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>82248.5453921828</td>\n",
       "      <td>1.9510604522</td>\n",
       "      <td>1.6510635788</td>\n",
       "      <td>1.4969157271</td>\n",
       "      <td>1.4126331716</td>\n",
       "      <td>1.3675334867</td>\n",
       "      <td>1.3305827734</td>\n",
       "      <td>1.2041108133</td>\n",
       "      <td>1.1855042538</td>\n",
       "      <td>1.0954151622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7220012926</td>\n",
       "      <td>0.7238290619</td>\n",
       "      <td>0.6360608349</td>\n",
       "      <td>0.6058543652</td>\n",
       "      <td>0.5200694420</td>\n",
       "      <td>0.4809785789</td>\n",
       "      <td>0.3995054883</td>\n",
       "      <td>0.3561296472</td>\n",
       "      <td>3.4129328933</td>\n",
       "      <td>0.5581608630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.0000000000</td>\n",
       "      <td>-56.4075096313</td>\n",
       "      <td>-72.7157275629</td>\n",
       "      <td>-32.4541981863</td>\n",
       "      <td>-5.6006071412</td>\n",
       "      <td>-42.1478983728</td>\n",
       "      <td>-26.1605059358</td>\n",
       "      <td>-41.5067960833</td>\n",
       "      <td>-50.9433688677</td>\n",
       "      <td>-13.4340663182</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.7575398591</td>\n",
       "      <td>-8.8870171409</td>\n",
       "      <td>-44.8077352038</td>\n",
       "      <td>-2.8248489029</td>\n",
       "      <td>-10.2953970750</td>\n",
       "      <td>-1.8553553378</td>\n",
       "      <td>-9.8952440476</td>\n",
       "      <td>-9.6179154524</td>\n",
       "      <td>-0.3074128415</td>\n",
       "      <td>-0.9949717454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>70796.7500000000</td>\n",
       "      <td>-0.9234789639</td>\n",
       "      <td>-0.5956024974</td>\n",
       "      <td>-0.8838765993</td>\n",
       "      <td>-0.8537282566</td>\n",
       "      <td>-0.6898532168</td>\n",
       "      <td>-0.7660942317</td>\n",
       "      <td>-0.5520711262</td>\n",
       "      <td>-0.2094919796</td>\n",
       "      <td>-0.6474770197</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2297098048</td>\n",
       "      <td>-0.5402664835</td>\n",
       "      <td>-0.1621803300</td>\n",
       "      <td>-0.3555819797</td>\n",
       "      <td>-0.3154703270</td>\n",
       "      <td>-0.3261599344</td>\n",
       "      <td>-0.0708471352</td>\n",
       "      <td>-0.0532485515</td>\n",
       "      <td>-0.2305596311</td>\n",
       "      <td>-0.3603043974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>141722.0000000000</td>\n",
       "      <td>0.0120736214</td>\n",
       "      <td>0.0663902608</td>\n",
       "      <td>0.1838678153</td>\n",
       "      <td>-0.0193594879</td>\n",
       "      <td>-0.0540596089</td>\n",
       "      <td>-0.2724355892</td>\n",
       "      <td>0.0390361877</td>\n",
       "      <td>0.0209696520</td>\n",
       "      <td>-0.0521569296</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0302814776</td>\n",
       "      <td>0.0083458070</td>\n",
       "      <td>-0.0122609847</td>\n",
       "      <td>0.0405734902</td>\n",
       "      <td>0.0182780212</td>\n",
       "      <td>-0.0528153757</td>\n",
       "      <td>0.0015018849</td>\n",
       "      <td>0.0111582113</td>\n",
       "      <td>-0.0006986655</td>\n",
       "      <td>-0.0025904910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>213359.5000000000</td>\n",
       "      <td>1.3153733393</td>\n",
       "      <td>0.8016868438</td>\n",
       "      <td>1.0371202905</td>\n",
       "      <td>0.7422077847</td>\n",
       "      <td>0.6142135083</td>\n",
       "      <td>0.4052848744</td>\n",
       "      <td>0.5687501336</td>\n",
       "      <td>0.3283030470</td>\n",
       "      <td>0.5907047932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1860012866</td>\n",
       "      <td>0.5287508178</td>\n",
       "      <td>0.1474742894</td>\n",
       "      <td>0.4382245391</td>\n",
       "      <td>0.3539892820</td>\n",
       "      <td>0.2408375726</td>\n",
       "      <td>0.0912790742</td>\n",
       "      <td>0.0778514865</td>\n",
       "      <td>0.7685321037</td>\n",
       "      <td>0.6406530857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>284803.0000000000</td>\n",
       "      <td>2.4549299912</td>\n",
       "      <td>21.4672029943</td>\n",
       "      <td>4.1878105990</td>\n",
       "      <td>16.4912171737</td>\n",
       "      <td>34.8016658767</td>\n",
       "      <td>23.9178371266</td>\n",
       "      <td>44.0544613632</td>\n",
       "      <td>20.0072083651</td>\n",
       "      <td>10.3928888247</td>\n",
       "      <td>...</td>\n",
       "      <td>27.2028391573</td>\n",
       "      <td>8.3619851917</td>\n",
       "      <td>22.5284116898</td>\n",
       "      <td>4.0228658904</td>\n",
       "      <td>7.5195886787</td>\n",
       "      <td>3.1192945290</td>\n",
       "      <td>11.1357398446</td>\n",
       "      <td>33.8478078189</td>\n",
       "      <td>180.1010270384</td>\n",
       "      <td>1.0349510685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID                V1                V2                V3  \\\n",
       "count 113842.0000000000 113842.0000000000 113842.0000000000 113842.0000000000   \n",
       "mean  142025.5278368265      0.0001972910      0.0012887948      0.0097173629   \n",
       "std    82248.5453921828      1.9510604522      1.6510635788      1.4969157271   \n",
       "min        3.0000000000    -56.4075096313    -72.7157275629    -32.4541981863   \n",
       "25%    70796.7500000000     -0.9234789639     -0.5956024974     -0.8838765993   \n",
       "50%   141722.0000000000      0.0120736214      0.0663902608      0.1838678153   \n",
       "75%   213359.5000000000      1.3153733393      0.8016868438      1.0371202905   \n",
       "max   284803.0000000000      2.4549299912     21.4672029943      4.1878105990   \n",
       "\n",
       "                     V4                V5                V6                V7  \\\n",
       "count 113842.0000000000 113842.0000000000 113842.0000000000 113842.0000000000   \n",
       "mean      -0.0041692083      0.0004749962      0.0051411577      0.0057690239   \n",
       "std        1.4126331716      1.3675334867      1.3305827734      1.2041108133   \n",
       "min       -5.6006071412    -42.1478983728    -26.1605059358    -41.5067960833   \n",
       "25%       -0.8537282566     -0.6898532168     -0.7660942317     -0.5520711262   \n",
       "50%       -0.0193594879     -0.0540596089     -0.2724355892      0.0390361877   \n",
       "75%        0.7422077847      0.6142135083      0.4052848744      0.5687501336   \n",
       "max       16.4912171737     34.8016658767     23.9178371266     44.0544613632   \n",
       "\n",
       "                     V8                V9  ...               V21  \\\n",
       "count 113842.0000000000 113842.0000000000  ... 113842.0000000000   \n",
       "mean      -0.0024505883     -0.0021070687  ...     -0.0012424691   \n",
       "std        1.1855042538      1.0954151622  ...      0.7220012926   \n",
       "min      -50.9433688677    -13.4340663182  ...    -22.7575398591   \n",
       "25%       -0.2094919796     -0.6474770197  ...     -0.2297098048   \n",
       "50%        0.0209696520     -0.0521569296  ...     -0.0302814776   \n",
       "75%        0.3283030470      0.5907047932  ...      0.1860012866   \n",
       "max       20.0072083651     10.3928888247  ...     27.2028391573   \n",
       "\n",
       "                    V22               V23               V24               V25  \\\n",
       "count 113842.0000000000 113842.0000000000 113842.0000000000 113842.0000000000   \n",
       "mean       0.0000004088     -0.0013174176     -0.0008841494      0.0016801536   \n",
       "std        0.7238290619      0.6360608349      0.6058543652      0.5200694420   \n",
       "min       -8.8870171409    -44.8077352038     -2.8248489029    -10.2953970750   \n",
       "25%       -0.5402664835     -0.1621803300     -0.3555819797     -0.3154703270   \n",
       "50%        0.0083458070     -0.0122609847      0.0405734902      0.0182780212   \n",
       "75%        0.5287508178      0.1474742894      0.4382245391      0.3539892820   \n",
       "max        8.3619851917     22.5284116898      4.0228658904      7.5195886787   \n",
       "\n",
       "                    V26               V27               V28               V29  \\\n",
       "count 113842.0000000000 113842.0000000000 113842.0000000000 113842.0000000000   \n",
       "mean      -0.0002933701     -0.0002337128     -0.0005080546      0.9272530175   \n",
       "std        0.4809785789      0.3995054883      0.3561296472      3.4129328933   \n",
       "min       -1.8553553378     -9.8952440476     -9.6179154524     -0.3074128415   \n",
       "25%       -0.3261599344     -0.0708471352     -0.0532485515     -0.2305596311   \n",
       "50%       -0.0528153757      0.0015018849      0.0111582113     -0.0006986655   \n",
       "75%        0.2408375726      0.0912790742      0.0778514865      0.7685321037   \n",
       "max        3.1192945290     11.1357398446     33.8478078189    180.1010270384   \n",
       "\n",
       "                    V30  \n",
       "count 113842.0000000000  \n",
       "mean       0.1162315431  \n",
       "std        0.5581608630  \n",
       "min       -0.9949717454  \n",
       "25%       -0.3603043974  \n",
       "50%       -0.0025904910  \n",
       "75%        0.6406530857  \n",
       "max        1.0349510685  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>-0.3382617524</td>\n",
       "      <td>1.1195933764</td>\n",
       "      <td>1.0443665516</td>\n",
       "      <td>-0.2221872767</td>\n",
       "      <td>0.4993608065</td>\n",
       "      <td>-0.2467611006</td>\n",
       "      <td>0.6515832065</td>\n",
       "      <td>0.0695385865</td>\n",
       "      <td>-0.7367273164</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6337526424</td>\n",
       "      <td>-0.1207940841</td>\n",
       "      <td>-0.3850499253</td>\n",
       "      <td>-0.0697330460</td>\n",
       "      <td>0.0941988340</td>\n",
       "      <td>0.2462193046</td>\n",
       "      <td>0.0830756493</td>\n",
       "      <td>-0.2559910571</td>\n",
       "      <td>-0.9948777594</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>0.9624960699</td>\n",
       "      <td>0.3284610261</td>\n",
       "      <td>-0.1714790542</td>\n",
       "      <td>2.1092040677</td>\n",
       "      <td>1.1295655713</td>\n",
       "      <td>1.6960376857</td>\n",
       "      <td>0.1077116073</td>\n",
       "      <td>0.5215021638</td>\n",
       "      <td>-1.1913111021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4024916614</td>\n",
       "      <td>-0.0485082212</td>\n",
       "      <td>-1.3718662945</td>\n",
       "      <td>0.3908138854</td>\n",
       "      <td>0.1999636575</td>\n",
       "      <td>0.0163706433</td>\n",
       "      <td>-0.0146053277</td>\n",
       "      <td>0.1689373297</td>\n",
       "      <td>-0.9947837733</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "      <td>1.1455243873</td>\n",
       "      <td>0.5750679681</td>\n",
       "      <td>0.1940084600</td>\n",
       "      <td>2.5981917450</td>\n",
       "      <td>-0.0922100227</td>\n",
       "      <td>-1.0444295837</td>\n",
       "      <td>0.5315875930</td>\n",
       "      <td>-0.2418881266</td>\n",
       "      <td>-0.8962871739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1197031003</td>\n",
       "      <td>-0.0765095276</td>\n",
       "      <td>0.6913204314</td>\n",
       "      <td>0.6339839771</td>\n",
       "      <td>0.0487412745</td>\n",
       "      <td>-0.0531919416</td>\n",
       "      <td>0.0162514988</td>\n",
       "      <td>0.1694962621</td>\n",
       "      <td>-0.9945018151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69</td>\n",
       "      <td>0.9270602489</td>\n",
       "      <td>-0.3236839717</td>\n",
       "      <td>0.3875848310</td>\n",
       "      <td>0.5444739886</td>\n",
       "      <td>0.2467873947</td>\n",
       "      <td>1.6503578045</td>\n",
       "      <td>-0.4275760175</td>\n",
       "      <td>0.6153706984</td>\n",
       "      <td>0.2262782750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0793594012</td>\n",
       "      <td>0.0966317457</td>\n",
       "      <td>-0.9925686689</td>\n",
       "      <td>0.0850958289</td>\n",
       "      <td>0.3774472053</td>\n",
       "      <td>0.0360964213</td>\n",
       "      <td>-0.0059602861</td>\n",
       "      <td>0.3313072032</td>\n",
       "      <td>-0.9944665703</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>-3.0052367224</td>\n",
       "      <td>2.6001382022</td>\n",
       "      <td>1.4836907373</td>\n",
       "      <td>-2.4184729551</td>\n",
       "      <td>0.3063264066</td>\n",
       "      <td>-0.8245745319</td>\n",
       "      <td>2.0654256393</td>\n",
       "      <td>-1.8293465894</td>\n",
       "      <td>4.0092585167</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1812684838</td>\n",
       "      <td>-0.1637465041</td>\n",
       "      <td>0.5158205258</td>\n",
       "      <td>0.1363184320</td>\n",
       "      <td>0.4600539675</td>\n",
       "      <td>-0.2512586378</td>\n",
       "      <td>-1.1057511571</td>\n",
       "      <td>-0.2870118074</td>\n",
       "      <td>-0.9943725843</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID            V1            V2            V3            V4            V5  \\\n",
       "0  10 -0.3382617524  1.1195933764  1.0443665516 -0.2221872767  0.4993608065   \n",
       "1  22  0.9624960699  0.3284610261 -0.1714790542  2.1092040677  1.1295655713   \n",
       "2  63  1.1455243873  0.5750679681  0.1940084600  2.5981917450 -0.0922100227   \n",
       "3  69  0.9270602489 -0.3236839717  0.3875848310  0.5444739886  0.2467873947   \n",
       "4  83 -3.0052367224  2.6001382022  1.4836907373 -2.4184729551  0.3063264066   \n",
       "\n",
       "             V6            V7            V8            V9  ...           V22  \\\n",
       "0 -0.2467611006  0.6515832065  0.0695385865 -0.7367273164  ... -0.6337526424   \n",
       "1  1.6960376857  0.1077116073  0.5215021638 -1.1913111021  ...  0.4024916614   \n",
       "2 -1.0444295837  0.5315875930 -0.2418881266 -0.8962871739  ... -0.1197031003   \n",
       "3  1.6503578045 -0.4275760175  0.6153706984  0.2262782750  ...  0.0793594012   \n",
       "4 -0.8245745319  2.0654256393 -1.8293465894  4.0092585167  ... -0.1812684838   \n",
       "\n",
       "            V23           V24           V25          V26           V27  \\\n",
       "0 -0.1207940841 -0.3850499253 -0.0697330460 0.0941988340  0.2462193046   \n",
       "1 -0.0485082212 -1.3718662945  0.3908138854 0.1999636575  0.0163706433   \n",
       "2 -0.0765095276  0.6913204314  0.6339839771 0.0487412745 -0.0531919416   \n",
       "3  0.0966317457 -0.9925686689  0.0850958289 0.3774472053  0.0360964213   \n",
       "4 -0.1637465041  0.5158205258  0.1363184320 0.4600539675 -0.2512586378   \n",
       "\n",
       "            V28           V29           V30  Class  \n",
       "0  0.0830756493 -0.2559910571 -0.9948777594      0  \n",
       "1 -0.0146053277  0.1689373297 -0.9947837733      0  \n",
       "2  0.0162514988  0.1694962621 -0.9945018151      0  \n",
       "3 -0.0059602861  0.3313072032 -0.9944665703      0  \n",
       "4 -1.1057511571 -0.2870118074 -0.9943725843      0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.read_csv(\"ano/val.csv\")\n",
    "df_val.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAA0x1</td>\n",
       "      <td>-1.3598071337</td>\n",
       "      <td>-0.0727811733</td>\n",
       "      <td>2.5363467380</td>\n",
       "      <td>1.3781552243</td>\n",
       "      <td>-0.3383207699</td>\n",
       "      <td>0.4623877778</td>\n",
       "      <td>0.2395985541</td>\n",
       "      <td>0.0986979013</td>\n",
       "      <td>0.3637869696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0183067779</td>\n",
       "      <td>0.2778375756</td>\n",
       "      <td>-0.1104739102</td>\n",
       "      <td>0.0669280749</td>\n",
       "      <td>0.1285393583</td>\n",
       "      <td>-0.1891148439</td>\n",
       "      <td>0.1335583767</td>\n",
       "      <td>-0.0210530535</td>\n",
       "      <td>1.7832739468</td>\n",
       "      <td>-0.9949834937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAA0x2</td>\n",
       "      <td>1.1918571113</td>\n",
       "      <td>0.2661507121</td>\n",
       "      <td>0.1664801134</td>\n",
       "      <td>0.4481540785</td>\n",
       "      <td>0.0600176493</td>\n",
       "      <td>-0.0823608088</td>\n",
       "      <td>-0.0788029833</td>\n",
       "      <td>0.0851016549</td>\n",
       "      <td>-0.2554251281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2257752480</td>\n",
       "      <td>-0.6386719528</td>\n",
       "      <td>0.1012880213</td>\n",
       "      <td>-0.3398464755</td>\n",
       "      <td>0.1671704044</td>\n",
       "      <td>0.1258945324</td>\n",
       "      <td>-0.0089830991</td>\n",
       "      <td>0.0147241692</td>\n",
       "      <td>-0.2698246349</td>\n",
       "      <td>-0.9949834937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAA0x5</td>\n",
       "      <td>-1.1582330935</td>\n",
       "      <td>0.8777367548</td>\n",
       "      <td>1.5487178465</td>\n",
       "      <td>0.4030339340</td>\n",
       "      <td>-0.4071933773</td>\n",
       "      <td>0.0959214625</td>\n",
       "      <td>0.5929407454</td>\n",
       "      <td>-0.2705326772</td>\n",
       "      <td>0.8177393082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0094306971</td>\n",
       "      <td>0.7982784946</td>\n",
       "      <td>-0.1374580796</td>\n",
       "      <td>0.1412669838</td>\n",
       "      <td>-0.2060095876</td>\n",
       "      <td>0.5022922242</td>\n",
       "      <td>0.2194222295</td>\n",
       "      <td>0.2151531475</td>\n",
       "      <td>0.6705791937</td>\n",
       "      <td>-0.9949599972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAA0x7</td>\n",
       "      <td>1.2296576345</td>\n",
       "      <td>0.1410035070</td>\n",
       "      <td>0.0453707736</td>\n",
       "      <td>1.2026127367</td>\n",
       "      <td>0.1918809886</td>\n",
       "      <td>0.2727081229</td>\n",
       "      <td>-0.0051590029</td>\n",
       "      <td>0.0812129399</td>\n",
       "      <td>0.4649599948</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1677162658</td>\n",
       "      <td>-0.2707097262</td>\n",
       "      <td>-0.1541037868</td>\n",
       "      <td>-0.7800554150</td>\n",
       "      <td>0.7501369358</td>\n",
       "      <td>-0.2572368459</td>\n",
       "      <td>0.0345074297</td>\n",
       "      <td>0.0051677689</td>\n",
       "      <td>-0.2376860197</td>\n",
       "      <td>-0.9949365007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAA0xc</td>\n",
       "      <td>0.3849782152</td>\n",
       "      <td>0.6161094592</td>\n",
       "      <td>-0.8742997026</td>\n",
       "      <td>-0.0940186260</td>\n",
       "      <td>2.9245843784</td>\n",
       "      <td>3.3170271683</td>\n",
       "      <td>0.4704546718</td>\n",
       "      <td>0.5382472284</td>\n",
       "      <td>-0.5588946124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0499236859</td>\n",
       "      <td>0.2384215122</td>\n",
       "      <td>0.0091298686</td>\n",
       "      <td>0.9967102096</td>\n",
       "      <td>-0.7673148272</td>\n",
       "      <td>-0.4922082953</td>\n",
       "      <td>0.0424724419</td>\n",
       "      <td>-0.0543373884</td>\n",
       "      <td>-0.1678194648</td>\n",
       "      <td>-0.9948660111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID            V1            V2            V3            V4  \\\n",
       "0  AAAA0x1 -1.3598071337 -0.0727811733  2.5363467380  1.3781552243   \n",
       "1  AAAA0x2  1.1918571113  0.2661507121  0.1664801134  0.4481540785   \n",
       "2  AAAA0x5 -1.1582330935  0.8777367548  1.5487178465  0.4030339340   \n",
       "3  AAAA0x7  1.2296576345  0.1410035070  0.0453707736  1.2026127367   \n",
       "4  AAAA0xc  0.3849782152  0.6161094592 -0.8742997026 -0.0940186260   \n",
       "\n",
       "             V5            V6            V7            V8            V9  ...  \\\n",
       "0 -0.3383207699  0.4623877778  0.2395985541  0.0986979013  0.3637869696  ...   \n",
       "1  0.0600176493 -0.0823608088 -0.0788029833  0.0851016549 -0.2554251281  ...   \n",
       "2 -0.4071933773  0.0959214625  0.5929407454 -0.2705326772  0.8177393082  ...   \n",
       "3  0.1918809886  0.2727081229 -0.0051590029  0.0812129399  0.4649599948  ...   \n",
       "4  2.9245843784  3.3170271683  0.4704546718  0.5382472284 -0.5588946124  ...   \n",
       "\n",
       "            V21           V22           V23           V24           V25  \\\n",
       "0 -0.0183067779  0.2778375756 -0.1104739102  0.0669280749  0.1285393583   \n",
       "1 -0.2257752480 -0.6386719528  0.1012880213 -0.3398464755  0.1671704044   \n",
       "2 -0.0094306971  0.7982784946 -0.1374580796  0.1412669838 -0.2060095876   \n",
       "3 -0.1677162658 -0.2707097262 -0.1541037868 -0.7800554150  0.7501369358   \n",
       "4  0.0499236859  0.2384215122  0.0091298686  0.9967102096 -0.7673148272   \n",
       "\n",
       "            V26           V27           V28           V29           V30  \n",
       "0 -0.1891148439  0.1335583767 -0.0210530535  1.7832739468 -0.9949834937  \n",
       "1  0.1258945324 -0.0089830991  0.0147241692 -0.2698246349 -0.9949834937  \n",
       "2  0.5022922242  0.2194222295  0.2151531475  0.6705791937 -0.9949599972  \n",
       "3 -0.2572368459  0.0345074297  0.0051677689 -0.2376860197 -0.9949365007  \n",
       "4 -0.4922082953  0.0424724419 -0.0543373884 -0.1678194648 -0.9948660111  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"ano/test.csv\")\n",
    "df_test.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8PRkxw4x4iU",
    "outputId": "5bdd9930-a595-422b-c4c0-540f22cd884f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check number of Rows and Columns\n",
      "(113842, 31)\n",
      "Check if any Missing values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Check number of Rows and Columns')\n",
    "print(df.shape)\n",
    "\n",
    "print('Check if any Missing values')\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "vs0ZTBwJzhbD"
   },
   "outputs": [],
   "source": [
    "data = df.drop(['ID'], axis=1)\n",
    "\n",
    "data_val_y = df_val['Class']\n",
    "data_val = df_val.drop(['ID','Class'], axis=1)\n",
    "\n",
    "data_test = df_test.drop(['ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PscqxyhNzhd1",
    "outputId": "3e1da2b3-dd38-457d-b17d-5b9f3c3bceaf"
   },
   "outputs": [],
   "source": [
    "X_train = data.values\n",
    "X_test = data_test.values\n",
    "X_val = data_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113842, 30)\n",
      "(142503, 30)\n",
      "(28462, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('normalizer', Normalizer()),\n",
    "                     ('scaler', MinMaxScaler())])\n",
    "\n",
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_val = pipeline.transform(X_val)\n",
    "X_test = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder - 2_layer encoder, 2_layer decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 113842 samples, validate on 28462 samples\n",
      "Epoch 1/100\n",
      " 51712/113842 [============>.................] - ETA: 0s - loss: 0.0309 - accuracy: 0.1253"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 13:50:34.400127: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "2022-09-28 13:50:34.400160: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-09-28 13:50:34.400167: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-09-28 13:50:34.404051: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-09-28 13:50:34.404078: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113842/113842 [==============================] - 1s 5us/sample - loss: 0.0177 - accuracy: 0.2887 - val_loss: 0.0038 - val_accuracy: 0.5605\n",
      "Epoch 2/100\n",
      "113842/113842 [==============================] - 0s 4us/sample - loss: 0.0021 - accuracy: 0.7030 - val_loss: 0.0010 - val_accuracy: 0.8019\n",
      "Epoch 3/100\n",
      "113842/113842 [==============================] - 1s 9us/sample - loss: 6.2837e-04 - accuracy: 0.8509 - val_loss: 3.6639e-04 - val_accuracy: 0.8856\n",
      "Epoch 4/100\n",
      "113842/113842 [==============================] - 1s 6us/sample - loss: 2.7098e-04 - accuracy: 0.9024 - val_loss: 1.9108e-04 - val_accuracy: 0.9213\n",
      "Epoch 5/100\n",
      "113842/113842 [==============================] - 1s 5us/sample - loss: 1.4760e-04 - accuracy: 0.9315 - val_loss: 1.1045e-04 - val_accuracy: 0.9418\n",
      "Epoch 6/100\n",
      "113842/113842 [==============================] - 1s 6us/sample - loss: 8.8929e-05 - accuracy: 0.9470 - val_loss: 7.1017e-05 - val_accuracy: 0.9510\n",
      "Epoch 7/100\n",
      "113842/113842 [==============================] - 1s 8us/sample - loss: 6.0640e-05 - accuracy: 0.9550 - val_loss: 5.0837e-05 - val_accuracy: 0.9583\n",
      "Epoch 8/100\n",
      "113842/113842 [==============================] - 0s 4us/sample - loss: 4.4809e-05 - accuracy: 0.9601 - val_loss: 3.3463e-05 - val_accuracy: 0.9671\n",
      "Epoch 9/100\n",
      "113842/113842 [==============================] - 1s 7us/sample - loss: 3.3743e-05 - accuracy: 0.9646 - val_loss: 3.2036e-05 - val_accuracy: 0.9642\n",
      "Epoch 10/100\n",
      "113842/113842 [==============================] - 1s 5us/sample - loss: 3.0125e-05 - accuracy: 0.9662 - val_loss: 4.6313e-05 - val_accuracy: 0.9540\n",
      "Epoch 11/100\n",
      "113842/113842 [==============================] - 0s 4us/sample - loss: 2.5926e-05 - accuracy: 0.9684 - val_loss: 2.8363e-05 - val_accuracy: 0.9640\n",
      "Epoch 12/100\n",
      "113842/113842 [==============================] - 1s 9us/sample - loss: 2.5591e-05 - accuracy: 0.9681 - val_loss: 2.9560e-05 - val_accuracy: 0.9634\n",
      "Epoch 13/100\n",
      "113842/113842 [==============================] - 1s 4us/sample - loss: 2.3195e-05 - accuracy: 0.9700 - val_loss: 2.1486e-05 - val_accuracy: 0.9710\n",
      "Epoch 14/100\n",
      "113842/113842 [==============================] - 0s 4us/sample - loss: 2.2098e-05 - accuracy: 0.9692 - val_loss: 2.9262e-05 - val_accuracy: 0.9662\n",
      "Epoch 15/100\n",
      "113842/113842 [==============================] - 1s 7us/sample - loss: 1.9739e-05 - accuracy: 0.9706 - val_loss: 1.6956e-05 - val_accuracy: 0.9717\n",
      "Epoch 16/100\n",
      "113842/113842 [==============================] - 1s 6us/sample - loss: 1.9048e-05 - accuracy: 0.9709 - val_loss: 2.3206e-05 - val_accuracy: 0.9657\n",
      "Epoch 17/100\n",
      "113842/113842 [==============================] - 1s 8us/sample - loss: 1.9369e-05 - accuracy: 0.9711 - val_loss: 1.0940e-05 - val_accuracy: 0.9779\n",
      "Epoch 18/100\n",
      "113842/113842 [==============================] - 1s 7us/sample - loss: 1.7914e-05 - accuracy: 0.9717 - val_loss: 2.2669e-05 - val_accuracy: 0.9720\n",
      "Epoch 19/100\n",
      "113842/113842 [==============================] - 1s 7us/sample - loss: 1.8035e-05 - accuracy: 0.9716 - val_loss: 1.0436e-05 - val_accuracy: 0.9793\n",
      "Epoch 20/100\n",
      "113842/113842 [==============================] - 0s 4us/sample - loss: 1.6805e-05 - accuracy: 0.9720 - val_loss: 3.3179e-05 - val_accuracy: 0.9589\n",
      "Epoch 21/100\n",
      "113842/113842 [==============================] - 1s 7us/sample - loss: 1.6703e-05 - accuracy: 0.9732 - val_loss: 8.5932e-06 - val_accuracy: 0.9803\n",
      "Epoch 22/100\n",
      "113842/113842 [==============================] - 1s 7us/sample - loss: 1.5919e-05 - accuracy: 0.9726 - val_loss: 1.4731e-05 - val_accuracy: 0.9718\n",
      "Epoch 23/100\n",
      "113842/113842 [==============================] - 1s 8us/sample - loss: 1.6193e-05 - accuracy: 0.9727 - val_loss: 9.0002e-06 - val_accuracy: 0.9819\n",
      "Epoch 24/100\n",
      "113842/113842 [==============================] - 1s 6us/sample - loss: 1.5492e-05 - accuracy: 0.9751 - val_loss: 3.0270e-05 - val_accuracy: 0.9597\n",
      "Epoch 25/100\n",
      "113842/113842 [==============================] - 1s 5us/sample - loss: 1.4608e-05 - accuracy: 0.9749 - val_loss: 1.4884e-05 - val_accuracy: 0.9745\n",
      "Epoch 26/100\n",
      "113842/113842 [==============================] - 0s 3us/sample - loss: 1.5433e-05 - accuracy: 0.9740 - val_loss: 8.8970e-06 - val_accuracy: 0.9817\n",
      "Epoch 27/100\n",
      "113842/113842 [==============================] - 1s 5us/sample - loss: 1.3980e-05 - accuracy: 0.9757 - val_loss: 9.7133e-06 - val_accuracy: 0.9778\n",
      "Epoch 28/100\n",
      "113842/113842 [==============================] - 1s 7us/sample - loss: 1.4761e-05 - accuracy: 0.9752 - val_loss: 1.9810e-05 - val_accuracy: 0.9679\n",
      "Epoch 29/100\n",
      "113842/113842 [==============================] - 1s 7us/sample - loss: 1.3883e-05 - accuracy: 0.9758 - val_loss: 8.4584e-06 - val_accuracy: 0.9826\n",
      "Epoch 30/100\n",
      "113842/113842 [==============================] - 1s 6us/sample - loss: 1.3396e-05 - accuracy: 0.9766 - val_loss: 1.3474e-05 - val_accuracy: 0.9784\n",
      "Epoch 31/100\n",
      "113842/113842 [==============================] - 1s 7us/sample - loss: 1.3303e-05 - accuracy: 0.9759 - val_loss: 1.5860e-05 - val_accuracy: 0.9724\n",
      "Epoch 32/100\n",
      "113842/113842 [==============================] - 0s 4us/sample - loss: 1.3250e-05 - accuracy: 0.9757 - val_loss: 7.1886e-06 - val_accuracy: 0.9835\n",
      "Epoch 33/100\n",
      "113842/113842 [==============================] - 1s 4us/sample - loss: 1.3092e-05 - accuracy: 0.9772 - val_loss: 6.2277e-06 - val_accuracy: 0.9832\n",
      "Epoch 34/100\n",
      "113842/113842 [==============================] - 0s 3us/sample - loss: 1.1977e-05 - accuracy: 0.9781 - val_loss: 1.4340e-05 - val_accuracy: 0.9815\n",
      "Epoch 35/100\n",
      "113842/113842 [==============================] - 1s 6us/sample - loss: 1.2364e-05 - accuracy: 0.9778 - val_loss: 2.5960e-05 - val_accuracy: 0.9779\n",
      "Epoch 36/100\n",
      "113842/113842 [==============================] - 1s 8us/sample - loss: 1.2324e-05 - accuracy: 0.9781 - val_loss: 6.4842e-06 - val_accuracy: 0.9836\n",
      "Epoch 37/100\n",
      "113842/113842 [==============================] - 1s 6us/sample - loss: 1.1844e-05 - accuracy: 0.9786 - val_loss: 1.2763e-05 - val_accuracy: 0.9791\n",
      "Epoch 38/100\n",
      "113842/113842 [==============================] - 1s 5us/sample - loss: 1.1339e-05 - accuracy: 0.9791 - val_loss: 1.0272e-05 - val_accuracy: 0.9808\n",
      "Epoch 39/100\n",
      "113842/113842 [==============================] - 1s 9us/sample - loss: 1.1426e-05 - accuracy: 0.9789 - val_loss: 6.3288e-06 - val_accuracy: 0.9827\n",
      "Epoch 40/100\n",
      "113842/113842 [==============================] - 1s 8us/sample - loss: 1.1939e-05 - accuracy: 0.9787 - val_loss: 6.7449e-06 - val_accuracy: 0.9820\n",
      "Epoch 41/100\n",
      "113842/113842 [==============================] - 1s 10us/sample - loss: 1.0783e-05 - accuracy: 0.9795 - val_loss: 5.8887e-06 - val_accuracy: 0.9843\n",
      "Epoch 42/100\n",
      "113842/113842 [==============================] - 1s 7us/sample - loss: 1.1361e-05 - accuracy: 0.9800 - val_loss: 1.2415e-05 - val_accuracy: 0.9789\n",
      "Epoch 43/100\n",
      "113842/113842 [==============================] - 1s 8us/sample - loss: 1.0388e-05 - accuracy: 0.9793 - val_loss: 1.8116e-05 - val_accuracy: 0.9752\n",
      "Epoch 44/100\n",
      "113842/113842 [==============================] - 1s 7us/sample - loss: 1.0973e-05 - accuracy: 0.9792 - val_loss: 1.0147e-05 - val_accuracy: 0.9778\n",
      "Epoch 45/100\n",
      "113842/113842 [==============================] - 0s 4us/sample - loss: 1.0072e-05 - accuracy: 0.9794 - val_loss: 6.1359e-06 - val_accuracy: 0.9829\n",
      "Epoch 46/100\n",
      "113842/113842 [==============================] - 0s 4us/sample - loss: 1.0381e-05 - accuracy: 0.9808 - val_loss: 8.8485e-06 - val_accuracy: 0.9781\n",
      "Epoch 47/100\n",
      "113842/113842 [==============================] - 1s 5us/sample - loss: 1.0872e-05 - accuracy: 0.9801 - val_loss: 6.1985e-06 - val_accuracy: 0.9817\n",
      "Epoch 48/100\n",
      "113842/113842 [==============================] - 0s 4us/sample - loss: 9.3350e-06 - accuracy: 0.9804 - val_loss: 1.5764e-05 - val_accuracy: 0.9769\n",
      "Epoch 49/100\n",
      "113842/113842 [==============================] - 1s 5us/sample - loss: 1.0530e-05 - accuracy: 0.9811 - val_loss: 9.1179e-06 - val_accuracy: 0.9771\n",
      "Epoch 50/100\n",
      "113842/113842 [==============================] - 1s 7us/sample - loss: 9.6936e-06 - accuracy: 0.9807 - val_loss: 5.1448e-06 - val_accuracy: 0.9866\n",
      "Epoch 51/100\n",
      "113842/113842 [==============================] - 1s 5us/sample - loss: 9.7095e-06 - accuracy: 0.9815 - val_loss: 1.5573e-05 - val_accuracy: 0.9798\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113842/113842 [==============================] - 1s 4us/sample - loss: 9.8473e-06 - accuracy: 0.9810 - val_loss: 5.3514e-06 - val_accuracy: 0.9838\n",
      "Epoch 53/100\n",
      "113842/113842 [==============================] - 1s 12us/sample - loss: 9.0788e-06 - accuracy: 0.9817 - val_loss: 9.3448e-06 - val_accuracy: 0.9826\n",
      "Epoch 54/100\n",
      "113842/113842 [==============================] - 1s 7us/sample - loss: 9.0910e-06 - accuracy: 0.9817 - val_loss: 6.7775e-06 - val_accuracy: 0.9842\n",
      "Epoch 55/100\n",
      "113842/113842 [==============================] - 1s 6us/sample - loss: 1.0131e-05 - accuracy: 0.9805 - val_loss: 7.8223e-06 - val_accuracy: 0.9838\n",
      "Epoch 56/100\n",
      "113842/113842 [==============================] - 1s 7us/sample - loss: 8.5664e-06 - accuracy: 0.9826 - val_loss: 9.4631e-06 - val_accuracy: 0.9794\n",
      "Epoch 57/100\n",
      "113842/113842 [==============================] - 1s 8us/sample - loss: 9.1416e-06 - accuracy: 0.9808 - val_loss: 1.0382e-05 - val_accuracy: 0.9781\n",
      "Epoch 58/100\n",
      "113842/113842 [==============================] - 1s 7us/sample - loss: 8.8395e-06 - accuracy: 0.9817 - val_loss: 4.9150e-06 - val_accuracy: 0.9846\n",
      "Epoch 59/100\n",
      "113842/113842 [==============================] - 1s 6us/sample - loss: 9.2604e-06 - accuracy: 0.9812 - val_loss: 2.7975e-05 - val_accuracy: 0.9752\n",
      "Epoch 60/100\n",
      "113842/113842 [==============================] - 1s 7us/sample - loss: 8.7543e-06 - accuracy: 0.9821 - val_loss: 1.8793e-05 - val_accuracy: 0.9798\n",
      "Epoch 61/100\n",
      "113842/113842 [==============================] - 1s 7us/sample - loss: 8.3257e-06 - accuracy: 0.9823 - val_loss: 7.3284e-06 - val_accuracy: 0.9773\n",
      "Epoch 62/100\n",
      "113842/113842 [==============================] - 1s 8us/sample - loss: 8.8160e-06 - accuracy: 0.9809 - val_loss: 1.2999e-05 - val_accuracy: 0.9809\n",
      "Epoch 63/100\n",
      "113842/113842 [==============================] - 1s 7us/sample - loss: 8.4754e-06 - accuracy: 0.9824 - val_loss: 5.8022e-06 - val_accuracy: 0.9831\n",
      "Epoch 64/100\n",
      "113842/113842 [==============================] - 0s 4us/sample - loss: 8.2447e-06 - accuracy: 0.9823 - val_loss: 1.0815e-05 - val_accuracy: 0.9792\n",
      "Epoch 65/100\n",
      "113842/113842 [==============================] - 1s 7us/sample - loss: 9.1090e-06 - accuracy: 0.9815 - val_loss: 3.8010e-06 - val_accuracy: 0.9892\n",
      "Epoch 66/100\n",
      "113842/113842 [==============================] - 0s 4us/sample - loss: 8.0498e-06 - accuracy: 0.9821 - val_loss: 5.4614e-06 - val_accuracy: 0.9846\n",
      "Epoch 67/100\n",
      "113842/113842 [==============================] - 1s 5us/sample - loss: 8.1550e-06 - accuracy: 0.9830 - val_loss: 1.0180e-05 - val_accuracy: 0.9807\n",
      "Epoch 68/100\n",
      "113842/113842 [==============================] - 1s 10us/sample - loss: 8.5480e-06 - accuracy: 0.9829 - val_loss: 3.6677e-06 - val_accuracy: 0.9882\n",
      "Epoch 69/100\n",
      "113842/113842 [==============================] - 0s 3us/sample - loss: 7.9913e-06 - accuracy: 0.9828 - val_loss: 9.1100e-06 - val_accuracy: 0.9751\n",
      "Epoch 70/100\n",
      "113842/113842 [==============================] - 0s 4us/sample - loss: 7.8070e-06 - accuracy: 0.9821 - val_loss: 7.2000e-06 - val_accuracy: 0.9815\n",
      "Epoch 71/100\n",
      "113842/113842 [==============================] - 0s 4us/sample - loss: 7.5357e-06 - accuracy: 0.9832 - val_loss: 7.9180e-06 - val_accuracy: 0.9798\n",
      "Epoch 72/100\n",
      "113842/113842 [==============================] - 0s 4us/sample - loss: 8.1606e-06 - accuracy: 0.9825 - val_loss: 7.9501e-06 - val_accuracy: 0.9811\n",
      "Epoch 73/100\n",
      "113842/113842 [==============================] - 0s 4us/sample - loss: 8.1952e-06 - accuracy: 0.9823 - val_loss: 6.0115e-06 - val_accuracy: 0.9827\n",
      "Epoch 74/100\n",
      "113842/113842 [==============================] - 0s 3us/sample - loss: 7.8902e-06 - accuracy: 0.9829 - val_loss: 1.9518e-05 - val_accuracy: 0.9717\n",
      "Epoch 75/100\n",
      "113842/113842 [==============================] - 1s 5us/sample - loss: 6.8192e-06 - accuracy: 0.9833 - val_loss: 6.1957e-06 - val_accuracy: 0.9822\n",
      "Epoch 76/100\n",
      "113842/113842 [==============================] - 1s 8us/sample - loss: 8.3327e-06 - accuracy: 0.9831 - val_loss: 6.4220e-06 - val_accuracy: 0.9830\n",
      "Epoch 77/100\n",
      "113842/113842 [==============================] - 1s 8us/sample - loss: 7.3465e-06 - accuracy: 0.9830 - val_loss: 5.5722e-06 - val_accuracy: 0.9874\n",
      "Epoch 78/100\n",
      "113842/113842 [==============================] - 0s 4us/sample - loss: 7.4409e-06 - accuracy: 0.9834 - val_loss: 9.3048e-06 - val_accuracy: 0.9840\n",
      "Epoch 79/100\n",
      "113842/113842 [==============================] - 0s 4us/sample - loss: 7.3953e-06 - accuracy: 0.9836 - val_loss: 2.4366e-05 - val_accuracy: 0.9761\n",
      "Epoch 80/100\n",
      "113842/113842 [==============================] - 1s 7us/sample - loss: 7.2892e-06 - accuracy: 0.9834 - val_loss: 9.6916e-06 - val_accuracy: 0.9791\n",
      "Epoch 81/100\n",
      "113842/113842 [==============================] - 0s 4us/sample - loss: 7.5299e-06 - accuracy: 0.9831 - val_loss: 1.2815e-05 - val_accuracy: 0.9825\n",
      "Epoch 82/100\n",
      "113842/113842 [==============================] - 1s 7us/sample - loss: 7.1463e-06 - accuracy: 0.9830 - val_loss: 6.6527e-06 - val_accuracy: 0.9798\n",
      "Epoch 83/100\n",
      "113842/113842 [==============================] - 1s 8us/sample - loss: 7.4220e-06 - accuracy: 0.9837 - val_loss: 4.1948e-06 - val_accuracy: 0.9853\n",
      "Epoch 84/100\n",
      "113842/113842 [==============================] - 1s 5us/sample - loss: 7.6375e-06 - accuracy: 0.9832 - val_loss: 6.7399e-06 - val_accuracy: 0.9845\n",
      "Epoch 85/100\n",
      "113842/113842 [==============================] - 1s 10us/sample - loss: 6.9575e-06 - accuracy: 0.9840 - val_loss: 4.0806e-06 - val_accuracy: 0.9834\n",
      "Epoch 86/100\n",
      "113842/113842 [==============================] - 1s 6us/sample - loss: 7.2393e-06 - accuracy: 0.9835 - val_loss: 5.3107e-06 - val_accuracy: 0.9851\n",
      "Epoch 87/100\n",
      "113842/113842 [==============================] - 1s 9us/sample - loss: 6.4522e-06 - accuracy: 0.9847 - val_loss: 5.0645e-06 - val_accuracy: 0.9877\n",
      "Epoch 88/100\n",
      "113842/113842 [==============================] - 1s 6us/sample - loss: 7.1677e-06 - accuracy: 0.9835 - val_loss: 4.6792e-06 - val_accuracy: 0.9866\n",
      "Epoch 89/100\n",
      "113842/113842 [==============================] - 1s 8us/sample - loss: 7.0626e-06 - accuracy: 0.9833 - val_loss: 7.1432e-06 - val_accuracy: 0.9816\n",
      "Epoch 90/100\n",
      "113842/113842 [==============================] - 1s 9us/sample - loss: 6.4096e-06 - accuracy: 0.9841 - val_loss: 8.6464e-06 - val_accuracy: 0.9831\n",
      "Epoch 91/100\n",
      "113842/113842 [==============================] - 1s 9us/sample - loss: 6.9273e-06 - accuracy: 0.9839 - val_loss: 9.4104e-06 - val_accuracy: 0.9814\n",
      "Epoch 92/100\n",
      "113842/113842 [==============================] - 1s 8us/sample - loss: 7.6461e-06 - accuracy: 0.9840 - val_loss: 4.3266e-06 - val_accuracy: 0.9843\n",
      "Epoch 93/100\n",
      "113842/113842 [==============================] - 1s 9us/sample - loss: 5.9427e-06 - accuracy: 0.9842 - val_loss: 3.9518e-06 - val_accuracy: 0.9879\n",
      "Epoch 94/100\n",
      "113842/113842 [==============================] - 1s 9us/sample - loss: 6.5905e-06 - accuracy: 0.9845 - val_loss: 4.8923e-06 - val_accuracy: 0.9898\n",
      "Epoch 95/100\n",
      "113842/113842 [==============================] - 1s 13us/sample - loss: 6.8373e-06 - accuracy: 0.9845 - val_loss: 3.5179e-06 - val_accuracy: 0.9887\n",
      "Epoch 96/100\n",
      "113842/113842 [==============================] - 1s 7us/sample - loss: 6.5390e-06 - accuracy: 0.9849 - val_loss: 1.0322e-05 - val_accuracy: 0.9798\n",
      "Epoch 97/100\n",
      "113842/113842 [==============================] - 1s 8us/sample - loss: 6.5202e-06 - accuracy: 0.9837 - val_loss: 7.0774e-06 - val_accuracy: 0.9829\n",
      "Epoch 98/100\n",
      "113842/113842 [==============================] - 1s 9us/sample - loss: 6.8213e-06 - accuracy: 0.9844 - val_loss: 3.5408e-06 - val_accuracy: 0.9888\n",
      "Epoch 99/100\n",
      "113842/113842 [==============================] - 1s 8us/sample - loss: 6.5377e-06 - accuracy: 0.9842 - val_loss: 4.1717e-06 - val_accuracy: 0.9881\n",
      "Epoch 100/100\n",
      "113842/113842 [==============================] - 1s 8us/sample - loss: 6.5013e-06 - accuracy: 0.9846 - val_loss: 3.3757e-06 - val_accuracy: 0.9865\n"
     ]
    }
   ],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "nb_epoch = 100\n",
    "batch_size = 512\n",
    "adamax = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    \n",
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 150\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\")(input_layer)\n",
    "encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
    "decoder = Dense(int(encoding_dim / 2), activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim)(decoder)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(optimizer=adamax, \n",
    "                    loss='mean_squared_error', \n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=f\"model.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs',\n",
    "                          histogram_freq=0,\n",
    "                          write_graph=True,\n",
    "                          write_images=True)\n",
    "\n",
    "history = autoencoder.fit(X_train, X_train,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_val, X_val),\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpointer, tensorboard]).history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원래값 - 예측값 ** 2으로 MSE 측정\n",
    "\n",
    "정상 데이터는 원래값에 근사할것\n",
    "\n",
    "비정상 데이터는 원래값과 차이가 있을것\n",
    "\n",
    "mse가 임계값 이상이면 비정상 데이터라고 판단\n",
    "\n",
    "1. 임계값 \n",
    "평균 + 2 * 표준편차 -> 더 좋은 성능을 보임\n",
    "\n",
    "2. 임계값\n",
    "중앙값 + 1.5 * IQR(사분위수 Q3 - Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    158\n",
       "1      9\n",
       "Name: true, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = load_model(f'model.h5')\n",
    "predictions = autoencoder.predict(X_val)\n",
    "mse = np.mean(np.power(X_val - predictions, 2), axis=1)\n",
    "    \n",
    "error_df = pd.DataFrame({'reconstruction_error': mse, 'true_class' : data_val_y})\n",
    "error_df.describe()\n",
    "\n",
    "means = error_df.describe()['reconstruction_error'].loc['mean']\n",
    "stds = error_df.describe()['reconstruction_error'].loc['std']\n",
    "\n",
    "median = error_df.describe()['reconstruction_error'].loc['50%']\n",
    "IQR = error_df.describe()['reconstruction_error'].loc['75%'] - error_df.describe()['reconstruction_error'].loc['25%']\n",
    "\n",
    "threshold = means + 2 * stds\n",
    "threshold2 = median + 1.5 * IQR\n",
    "\n",
    "\n",
    "tests = np.where(mse>=threshold, 1, 0)\n",
    "\n",
    "df = pd.DataFrame({'mse' : mse, 'test' : tests, 'true' : data_val_y})\n",
    "df[df['test'] == 1]['true'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kfold로 trainset을 일정량씩 사용하여 ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LcNYk-Mu1LQI",
    "outputId": "a418097a-eba2-4035-ce19-3712d6c0200f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx :  0\n",
      "Train on 91073 samples, validate on 22769 samples\n",
      "Epoch 1/100\n",
      "11776/91073 [==>...........................] - ETA: 3s - loss: 0.2468 - accuracy: 0.0296"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 13:51:49.219920: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "2022-09-28 13:51:49.220030: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-09-28 13:51:49.220062: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-09-28 13:51:49.233905: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-09-28 13:51:49.233994: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.1275 - accuracy: 0.2580 - val_loss: 0.0949 - val_accuracy: 0.3156\n",
      "Epoch 2/100\n",
      "91073/91073 [==============================] - 0s 5us/sample - loss: 0.0734 - accuracy: 0.5186 - val_loss: 0.0694 - val_accuracy: 0.5323\n",
      "Epoch 3/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0523 - accuracy: 0.6743 - val_loss: 0.0477 - val_accuracy: 0.6986\n",
      "Epoch 4/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0380 - accuracy: 0.7815 - val_loss: 0.0358 - val_accuracy: 0.7813\n",
      "Epoch 5/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0297 - accuracy: 0.8210 - val_loss: 0.0295 - val_accuracy: 0.8138\n",
      "Epoch 6/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0260 - accuracy: 0.8383 - val_loss: 0.0268 - val_accuracy: 0.8198\n",
      "Epoch 7/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0224 - accuracy: 0.8546 - val_loss: 0.0215 - val_accuracy: 0.8563\n",
      "Epoch 8/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0187 - accuracy: 0.8807 - val_loss: 0.0185 - val_accuracy: 0.8799\n",
      "Epoch 9/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0170 - accuracy: 0.8952 - val_loss: 0.0172 - val_accuracy: 0.8938\n",
      "Epoch 10/100\n",
      "91073/91073 [==============================] - 1s 6us/sample - loss: 0.0153 - accuracy: 0.9092 - val_loss: 0.0152 - val_accuracy: 0.9016\n",
      "Epoch 11/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0132 - accuracy: 0.9220 - val_loss: 0.0128 - val_accuracy: 0.9262\n",
      "Epoch 12/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0109 - accuracy: 0.9397 - val_loss: 0.0115 - val_accuracy: 0.9366\n",
      "Epoch 13/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0100 - accuracy: 0.9483 - val_loss: 0.0107 - val_accuracy: 0.9449\n",
      "Epoch 14/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0096 - accuracy: 0.9509 - val_loss: 0.0106 - val_accuracy: 0.9487\n",
      "Epoch 15/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0093 - accuracy: 0.9536 - val_loss: 0.0104 - val_accuracy: 0.9480\n",
      "Epoch 16/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0092 - accuracy: 0.9560 - val_loss: 0.0100 - val_accuracy: 0.9544\n",
      "Epoch 17/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0091 - accuracy: 0.9564 - val_loss: 0.0101 - val_accuracy: 0.9539\n",
      "Epoch 18/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0090 - accuracy: 0.9569 - val_loss: 0.0102 - val_accuracy: 0.9462\n",
      "Epoch 19/100\n",
      "91073/91073 [==============================] - 1s 11us/sample - loss: 0.0089 - accuracy: 0.9579 - val_loss: 0.0098 - val_accuracy: 0.9537\n",
      "Epoch 20/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0088 - accuracy: 0.9593 - val_loss: 0.0098 - val_accuracy: 0.9541\n",
      "Epoch 21/100\n",
      "91073/91073 [==============================] - 1s 11us/sample - loss: 0.0089 - accuracy: 0.9575 - val_loss: 0.0098 - val_accuracy: 0.9565\n",
      "Epoch 22/100\n",
      "91073/91073 [==============================] - 1s 11us/sample - loss: 0.0087 - accuracy: 0.9598 - val_loss: 0.0096 - val_accuracy: 0.9552\n",
      "Epoch 23/100\n",
      "91073/91073 [==============================] - 0s 4us/sample - loss: 0.0087 - accuracy: 0.9608 - val_loss: 0.0095 - val_accuracy: 0.9570\n",
      "Epoch 24/100\n",
      "91073/91073 [==============================] - 0s 5us/sample - loss: 0.0086 - accuracy: 0.9604 - val_loss: 0.0095 - val_accuracy: 0.9598\n",
      "Epoch 25/100\n",
      "91073/91073 [==============================] - 0s 4us/sample - loss: 0.0086 - accuracy: 0.9613 - val_loss: 0.0094 - val_accuracy: 0.9584\n",
      "Epoch 26/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0083 - accuracy: 0.9614 - val_loss: 0.0083 - val_accuracy: 0.9601\n",
      "Epoch 27/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0071 - accuracy: 0.9616 - val_loss: 0.0064 - val_accuracy: 0.9608\n",
      "Epoch 28/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0057 - accuracy: 0.9668 - val_loss: 0.0053 - val_accuracy: 0.9657\n",
      "Epoch 29/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0053 - accuracy: 0.9676 - val_loss: 0.0059 - val_accuracy: 0.9535\n",
      "Epoch 30/100\n",
      "91073/91073 [==============================] - 1s 13us/sample - loss: 0.0052 - accuracy: 0.9690 - val_loss: 0.0050 - val_accuracy: 0.9648\n",
      "Epoch 31/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0052 - accuracy: 0.9690 - val_loss: 0.0048 - val_accuracy: 0.9682\n",
      "Epoch 32/100\n",
      "91073/91073 [==============================] - 1s 6us/sample - loss: 0.0051 - accuracy: 0.9704 - val_loss: 0.0053 - val_accuracy: 0.9665\n",
      "Epoch 33/100\n",
      "91073/91073 [==============================] - 1s 12us/sample - loss: 0.0051 - accuracy: 0.9685 - val_loss: 0.0047 - val_accuracy: 0.9702\n",
      "Epoch 34/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0050 - accuracy: 0.9703 - val_loss: 0.0051 - val_accuracy: 0.9665\n",
      "Epoch 35/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0051 - accuracy: 0.9697 - val_loss: 0.0048 - val_accuracy: 0.9689\n",
      "Epoch 36/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0049 - accuracy: 0.9705 - val_loss: 0.0049 - val_accuracy: 0.9642\n",
      "Epoch 37/100\n",
      "91073/91073 [==============================] - 1s 11us/sample - loss: 0.0050 - accuracy: 0.9697 - val_loss: 0.0048 - val_accuracy: 0.9700\n",
      "Epoch 38/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0049 - accuracy: 0.9702 - val_loss: 0.0055 - val_accuracy: 0.9622\n",
      "Epoch 39/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0049 - accuracy: 0.9713 - val_loss: 0.0047 - val_accuracy: 0.9719\n",
      "Epoch 40/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0049 - accuracy: 0.9708 - val_loss: 0.0048 - val_accuracy: 0.9671\n",
      "Epoch 41/100\n",
      "91073/91073 [==============================] - 1s 6us/sample - loss: 0.0049 - accuracy: 0.9714 - val_loss: 0.0044 - val_accuracy: 0.9716\n",
      "Epoch 42/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0048 - accuracy: 0.9716 - val_loss: 0.0047 - val_accuracy: 0.9687\n",
      "Epoch 43/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0049 - accuracy: 0.9707 - val_loss: 0.0045 - val_accuracy: 0.9723\n",
      "Epoch 44/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0048 - accuracy: 0.9712 - val_loss: 0.0045 - val_accuracy: 0.9729\n",
      "Epoch 45/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0048 - accuracy: 0.9718 - val_loss: 0.0048 - val_accuracy: 0.9666\n",
      "Epoch 46/100\n",
      "91073/91073 [==============================] - 0s 4us/sample - loss: 0.0048 - accuracy: 0.9720 - val_loss: 0.0045 - val_accuracy: 0.9729\n",
      "Epoch 47/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0048 - accuracy: 0.9715 - val_loss: 0.0048 - val_accuracy: 0.9671\n",
      "Epoch 48/100\n",
      "91073/91073 [==============================] - 1s 11us/sample - loss: 0.0047 - accuracy: 0.9721 - val_loss: 0.0043 - val_accuracy: 0.9746\n",
      "Epoch 49/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0048 - accuracy: 0.9716 - val_loss: 0.0046 - val_accuracy: 0.9722\n",
      "Epoch 50/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0047 - accuracy: 0.9728 - val_loss: 0.0050 - val_accuracy: 0.9714\n",
      "Epoch 51/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0047 - accuracy: 0.9734 - val_loss: 0.0044 - val_accuracy: 0.9711\n",
      "Epoch 52/100\n",
      "91073/91073 [==============================] - 1s 6us/sample - loss: 0.0047 - accuracy: 0.9723 - val_loss: 0.0044 - val_accuracy: 0.9713\n",
      "Epoch 53/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0047 - accuracy: 0.9725 - val_loss: 0.0044 - val_accuracy: 0.9725\n",
      "Epoch 54/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0047 - accuracy: 0.9719 - val_loss: 0.0044 - val_accuracy: 0.9707\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0047 - accuracy: 0.9734 - val_loss: 0.0049 - val_accuracy: 0.9723\n",
      "Epoch 56/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0047 - accuracy: 0.9728 - val_loss: 0.0050 - val_accuracy: 0.9646\n",
      "Epoch 57/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0046 - accuracy: 0.9726 - val_loss: 0.0044 - val_accuracy: 0.9733\n",
      "Epoch 58/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0046 - accuracy: 0.9729 - val_loss: 0.0048 - val_accuracy: 0.9664\n",
      "Epoch 59/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0047 - accuracy: 0.9722 - val_loss: 0.0043 - val_accuracy: 0.9733\n",
      "Epoch 60/100\n",
      "91073/91073 [==============================] - 0s 4us/sample - loss: 0.0045 - accuracy: 0.9738 - val_loss: 0.0041 - val_accuracy: 0.9746\n",
      "Epoch 61/100\n",
      "91073/91073 [==============================] - 1s 12us/sample - loss: 0.0040 - accuracy: 0.9745 - val_loss: 0.0038 - val_accuracy: 0.9758\n",
      "Epoch 62/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0035 - accuracy: 0.9769 - val_loss: 0.0030 - val_accuracy: 0.9799\n",
      "Epoch 63/100\n",
      "91073/91073 [==============================] - 0s 5us/sample - loss: 0.0030 - accuracy: 0.9816 - val_loss: 0.0033 - val_accuracy: 0.9784\n",
      "Epoch 64/100\n",
      "91073/91073 [==============================] - 0s 4us/sample - loss: 0.0029 - accuracy: 0.9815 - val_loss: 0.0032 - val_accuracy: 0.9816\n",
      "Epoch 65/100\n",
      "91073/91073 [==============================] - 0s 3us/sample - loss: 0.0029 - accuracy: 0.9830 - val_loss: 0.0032 - val_accuracy: 0.9775\n",
      "Epoch 66/100\n",
      "91073/91073 [==============================] - 0s 4us/sample - loss: 0.0029 - accuracy: 0.9821 - val_loss: 0.0031 - val_accuracy: 0.9769\n",
      "Epoch 67/100\n",
      "91073/91073 [==============================] - 0s 4us/sample - loss: 0.0029 - accuracy: 0.9827 - val_loss: 0.0033 - val_accuracy: 0.9773\n",
      "Epoch 68/100\n",
      "91073/91073 [==============================] - 0s 4us/sample - loss: 0.0029 - accuracy: 0.9828 - val_loss: 0.0028 - val_accuracy: 0.9796\n",
      "Epoch 69/100\n",
      "91073/91073 [==============================] - 0s 5us/sample - loss: 0.0028 - accuracy: 0.9827 - val_loss: 0.0029 - val_accuracy: 0.9788\n",
      "Epoch 70/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0028 - accuracy: 0.9831 - val_loss: 0.0026 - val_accuracy: 0.9830\n",
      "Epoch 71/100\n",
      "91073/91073 [==============================] - 1s 6us/sample - loss: 0.0028 - accuracy: 0.9830 - val_loss: 0.0031 - val_accuracy: 0.9776\n",
      "Epoch 72/100\n",
      "91073/91073 [==============================] - 0s 5us/sample - loss: 0.0028 - accuracy: 0.9832 - val_loss: 0.0028 - val_accuracy: 0.9795\n",
      "Epoch 73/100\n",
      "91073/91073 [==============================] - 1s 12us/sample - loss: 0.0028 - accuracy: 0.9834 - val_loss: 0.0030 - val_accuracy: 0.9765\n",
      "Epoch 74/100\n",
      "91073/91073 [==============================] - 1s 6us/sample - loss: 0.0027 - accuracy: 0.9827 - val_loss: 0.0029 - val_accuracy: 0.9810\n",
      "Epoch 75/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0027 - accuracy: 0.9834 - val_loss: 0.0026 - val_accuracy: 0.9832\n",
      "Epoch 76/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0027 - accuracy: 0.9837 - val_loss: 0.0031 - val_accuracy: 0.9793\n",
      "Epoch 77/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0027 - accuracy: 0.9838 - val_loss: 0.0030 - val_accuracy: 0.9805\n",
      "Epoch 78/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0027 - accuracy: 0.9832 - val_loss: 0.0028 - val_accuracy: 0.9801\n",
      "Epoch 79/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0027 - accuracy: 0.9839 - val_loss: 0.0028 - val_accuracy: 0.9797\n",
      "Epoch 80/100\n",
      "91073/91073 [==============================] - 1s 11us/sample - loss: 0.0027 - accuracy: 0.9835 - val_loss: 0.0030 - val_accuracy: 0.9774\n",
      "Epoch 81/100\n",
      "91073/91073 [==============================] - 1s 11us/sample - loss: 0.0026 - accuracy: 0.9841 - val_loss: 0.0029 - val_accuracy: 0.9813\n",
      "Epoch 82/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0027 - accuracy: 0.9839 - val_loss: 0.0028 - val_accuracy: 0.9851\n",
      "Epoch 83/100\n",
      "91073/91073 [==============================] - 0s 4us/sample - loss: 0.0026 - accuracy: 0.9839 - val_loss: 0.0028 - val_accuracy: 0.9837\n",
      "Epoch 84/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0026 - accuracy: 0.9839 - val_loss: 0.0028 - val_accuracy: 0.9791\n",
      "Epoch 85/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0026 - accuracy: 0.9838 - val_loss: 0.0026 - val_accuracy: 0.9838\n",
      "Epoch 86/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0026 - accuracy: 0.9842 - val_loss: 0.0028 - val_accuracy: 0.9804\n",
      "Epoch 87/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0026 - accuracy: 0.9839 - val_loss: 0.0030 - val_accuracy: 0.9807\n",
      "Epoch 88/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0026 - accuracy: 0.9843 - val_loss: 0.0027 - val_accuracy: 0.9804\n",
      "Epoch 89/100\n",
      "91073/91073 [==============================] - 1s 6us/sample - loss: 0.0026 - accuracy: 0.9844 - val_loss: 0.0028 - val_accuracy: 0.9805\n",
      "Epoch 90/100\n",
      "91073/91073 [==============================] - 0s 5us/sample - loss: 0.0026 - accuracy: 0.9842 - val_loss: 0.0029 - val_accuracy: 0.9826\n",
      "Epoch 91/100\n",
      "91073/91073 [==============================] - 0s 5us/sample - loss: 0.0026 - accuracy: 0.9848 - val_loss: 0.0030 - val_accuracy: 0.9823\n",
      "Epoch 92/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0026 - accuracy: 0.9842 - val_loss: 0.0027 - val_accuracy: 0.9812\n",
      "Epoch 93/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0025 - accuracy: 0.9843 - val_loss: 0.0028 - val_accuracy: 0.9780\n",
      "Epoch 94/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0025 - accuracy: 0.9850 - val_loss: 0.0032 - val_accuracy: 0.9671\n",
      "Epoch 95/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0025 - accuracy: 0.9844 - val_loss: 0.0028 - val_accuracy: 0.9829\n",
      "Epoch 96/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0025 - accuracy: 0.9844 - val_loss: 0.0028 - val_accuracy: 0.9779\n",
      "Epoch 97/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0025 - accuracy: 0.9847 - val_loss: 0.0028 - val_accuracy: 0.9802\n",
      "Epoch 98/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0025 - accuracy: 0.9844 - val_loss: 0.0027 - val_accuracy: 0.9787\n",
      "Epoch 99/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0024 - accuracy: 0.9849 - val_loss: 0.0027 - val_accuracy: 0.9817\n",
      "Epoch 100/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0025 - accuracy: 0.9850 - val_loss: 0.0028 - val_accuracy: 0.9797\n",
      "idx :  1\n",
      "Train on 91073 samples, validate on 22769 samples\n",
      "Epoch 1/100\n",
      "33280/91073 [=========>....................] - ETA: 0s - loss: 0.2033 - accuracy: 0.0672"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 13:53:03.645882: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "2022-09-28 13:53:03.645915: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-09-28 13:53:03.645921: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-09-28 13:53:03.649426: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-09-28 13:53:03.649447: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91073/91073 [==============================] - 1s 11us/sample - loss: 0.1469 - accuracy: 0.1441 - val_loss: 0.0950 - val_accuracy: 0.2510\n",
      "Epoch 2/100\n",
      "91073/91073 [==============================] - 0s 3us/sample - loss: 0.0706 - accuracy: 0.5567 - val_loss: 0.0562 - val_accuracy: 0.6168\n",
      "Epoch 3/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0455 - accuracy: 0.7284 - val_loss: 0.0374 - val_accuracy: 0.7610\n",
      "Epoch 4/100\n",
      "91073/91073 [==============================] - 1s 12us/sample - loss: 0.0299 - accuracy: 0.8116 - val_loss: 0.0250 - val_accuracy: 0.8382\n",
      "Epoch 5/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0202 - accuracy: 0.8701 - val_loss: 0.0178 - val_accuracy: 0.8872\n",
      "Epoch 6/100\n",
      "91073/91073 [==============================] - 0s 5us/sample - loss: 0.0158 - accuracy: 0.9036 - val_loss: 0.0157 - val_accuracy: 0.9054\n",
      "Epoch 7/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0145 - accuracy: 0.9126 - val_loss: 0.0152 - val_accuracy: 0.9057\n",
      "Epoch 8/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0138 - accuracy: 0.9147 - val_loss: 0.0143 - val_accuracy: 0.9010\n",
      "Epoch 9/100\n",
      "91073/91073 [==============================] - 0s 4us/sample - loss: 0.0128 - accuracy: 0.9213 - val_loss: 0.0126 - val_accuracy: 0.9178\n",
      "Epoch 10/100\n",
      "91073/91073 [==============================] - 0s 5us/sample - loss: 0.0120 - accuracy: 0.9264 - val_loss: 0.0127 - val_accuracy: 0.9133\n",
      "Epoch 11/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0117 - accuracy: 0.9312 - val_loss: 0.0119 - val_accuracy: 0.9224\n",
      "Epoch 12/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0113 - accuracy: 0.9350 - val_loss: 0.0112 - val_accuracy: 0.9307\n",
      "Epoch 13/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0107 - accuracy: 0.9409 - val_loss: 0.0108 - val_accuracy: 0.9345\n",
      "Epoch 14/100\n",
      "91073/91073 [==============================] - 1s 6us/sample - loss: 0.0102 - accuracy: 0.9465 - val_loss: 0.0100 - val_accuracy: 0.9451\n",
      "Epoch 15/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0098 - accuracy: 0.9508 - val_loss: 0.0101 - val_accuracy: 0.9469\n",
      "Epoch 16/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0096 - accuracy: 0.9531 - val_loss: 0.0095 - val_accuracy: 0.9516\n",
      "Epoch 17/100\n",
      "91073/91073 [==============================] - 1s 12us/sample - loss: 0.0095 - accuracy: 0.9540 - val_loss: 0.0101 - val_accuracy: 0.9292\n",
      "Epoch 18/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0092 - accuracy: 0.9568 - val_loss: 0.0091 - val_accuracy: 0.9546\n",
      "Epoch 19/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0092 - accuracy: 0.9556 - val_loss: 0.0095 - val_accuracy: 0.9512\n",
      "Epoch 20/100\n",
      "91073/91073 [==============================] - 1s 12us/sample - loss: 0.0090 - accuracy: 0.9591 - val_loss: 0.0089 - val_accuracy: 0.9573\n",
      "Epoch 21/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0092 - accuracy: 0.9565 - val_loss: 0.0090 - val_accuracy: 0.9537\n",
      "Epoch 22/100\n",
      "91073/91073 [==============================] - 1s 11us/sample - loss: 0.0091 - accuracy: 0.9593 - val_loss: 0.0088 - val_accuracy: 0.9592\n",
      "Epoch 23/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0088 - accuracy: 0.9608 - val_loss: 0.0090 - val_accuracy: 0.9534\n",
      "Epoch 24/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0089 - accuracy: 0.9598 - val_loss: 0.0084 - val_accuracy: 0.9583\n",
      "Epoch 25/100\n",
      "91073/91073 [==============================] - 0s 5us/sample - loss: 0.0083 - accuracy: 0.9622 - val_loss: 0.0087 - val_accuracy: 0.9563\n",
      "Epoch 26/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0076 - accuracy: 0.9637 - val_loss: 0.0065 - val_accuracy: 0.9650\n",
      "Epoch 27/100\n",
      "91073/91073 [==============================] - 0s 4us/sample - loss: 0.0073 - accuracy: 0.9626 - val_loss: 0.0065 - val_accuracy: 0.9665\n",
      "Epoch 28/100\n",
      "91073/91073 [==============================] - 1s 11us/sample - loss: 0.0072 - accuracy: 0.9649 - val_loss: 0.0062 - val_accuracy: 0.9686\n",
      "Epoch 29/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0072 - accuracy: 0.9644 - val_loss: 0.0062 - val_accuracy: 0.9643\n",
      "Epoch 30/100\n",
      "91073/91073 [==============================] - 0s 4us/sample - loss: 0.0069 - accuracy: 0.9674 - val_loss: 0.0069 - val_accuracy: 0.9580\n",
      "Epoch 31/100\n",
      "91073/91073 [==============================] - 0s 4us/sample - loss: 0.0068 - accuracy: 0.9668 - val_loss: 0.0061 - val_accuracy: 0.9665\n",
      "Epoch 32/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0069 - accuracy: 0.9647 - val_loss: 0.0075 - val_accuracy: 0.9545\n",
      "Epoch 33/100\n",
      "91073/91073 [==============================] - 1s 11us/sample - loss: 0.0068 - accuracy: 0.9661 - val_loss: 0.0086 - val_accuracy: 0.9514\n",
      "Epoch 34/100\n",
      "91073/91073 [==============================] - 0s 5us/sample - loss: 0.0071 - accuracy: 0.9641 - val_loss: 0.0059 - val_accuracy: 0.9660\n",
      "Epoch 35/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0068 - accuracy: 0.9656 - val_loss: 0.0077 - val_accuracy: 0.9582\n",
      "Epoch 36/100\n",
      "91073/91073 [==============================] - 1s 11us/sample - loss: 0.0068 - accuracy: 0.9660 - val_loss: 0.0062 - val_accuracy: 0.9687\n",
      "Epoch 37/100\n",
      "91073/91073 [==============================] - 1s 11us/sample - loss: 0.0067 - accuracy: 0.9675 - val_loss: 0.0066 - val_accuracy: 0.9650\n",
      "Epoch 38/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0069 - accuracy: 0.9646 - val_loss: 0.0061 - val_accuracy: 0.9670\n",
      "Epoch 39/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0067 - accuracy: 0.9675 - val_loss: 0.0070 - val_accuracy: 0.9653\n",
      "Epoch 40/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0067 - accuracy: 0.9677 - val_loss: 0.0062 - val_accuracy: 0.9665\n",
      "Epoch 41/100\n",
      "91073/91073 [==============================] - 1s 6us/sample - loss: 0.0067 - accuracy: 0.9682 - val_loss: 0.0061 - val_accuracy: 0.9693\n",
      "Epoch 42/100\n",
      "91073/91073 [==============================] - 0s 4us/sample - loss: 0.0068 - accuracy: 0.9670 - val_loss: 0.0068 - val_accuracy: 0.9657\n",
      "Epoch 43/100\n",
      "91073/91073 [==============================] - 1s 13us/sample - loss: 0.0067 - accuracy: 0.9677 - val_loss: 0.0069 - val_accuracy: 0.9618\n",
      "Epoch 44/100\n",
      "91073/91073 [==============================] - 1s 13us/sample - loss: 0.0066 - accuracy: 0.9668 - val_loss: 0.0060 - val_accuracy: 0.9648\n",
      "Epoch 45/100\n",
      "91073/91073 [==============================] - 1s 12us/sample - loss: 0.0065 - accuracy: 0.9684 - val_loss: 0.0060 - val_accuracy: 0.9676\n",
      "Epoch 46/100\n",
      "91073/91073 [==============================] - 0s 4us/sample - loss: 0.0065 - accuracy: 0.9685 - val_loss: 0.0096 - val_accuracy: 0.9461\n",
      "Epoch 47/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0068 - accuracy: 0.9667 - val_loss: 0.0059 - val_accuracy: 0.9706\n",
      "Epoch 48/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0069 - accuracy: 0.9678 - val_loss: 0.0057 - val_accuracy: 0.9728\n",
      "Epoch 49/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0066 - accuracy: 0.9681 - val_loss: 0.0058 - val_accuracy: 0.9697\n",
      "Epoch 50/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0064 - accuracy: 0.9679 - val_loss: 0.0053 - val_accuracy: 0.9733\n",
      "Epoch 51/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0067 - accuracy: 0.9660 - val_loss: 0.0060 - val_accuracy: 0.9693\n",
      "Epoch 52/100\n",
      "91073/91073 [==============================] - 1s 11us/sample - loss: 0.0062 - accuracy: 0.9698 - val_loss: 0.0047 - val_accuracy: 0.9765\n",
      "Epoch 53/100\n",
      "91073/91073 [==============================] - 1s 6us/sample - loss: 0.0061 - accuracy: 0.9713 - val_loss: 0.0046 - val_accuracy: 0.9734\n",
      "Epoch 54/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0057 - accuracy: 0.9734 - val_loss: 0.0054 - val_accuracy: 0.9598\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91073/91073 [==============================] - 1s 6us/sample - loss: 0.0057 - accuracy: 0.9724 - val_loss: 0.0058 - val_accuracy: 0.9599\n",
      "Epoch 56/100\n",
      "91073/91073 [==============================] - 0s 3us/sample - loss: 0.0061 - accuracy: 0.9706 - val_loss: 0.0058 - val_accuracy: 0.9650\n",
      "Epoch 57/100\n",
      "91073/91073 [==============================] - 0s 4us/sample - loss: 0.0059 - accuracy: 0.9719 - val_loss: 0.0068 - val_accuracy: 0.9511\n",
      "Epoch 58/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0060 - accuracy: 0.9713 - val_loss: 0.0058 - val_accuracy: 0.9567\n",
      "Epoch 59/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0059 - accuracy: 0.9723 - val_loss: 0.0055 - val_accuracy: 0.9654\n",
      "Epoch 60/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0051 - accuracy: 0.9741 - val_loss: 0.0053 - val_accuracy: 0.9627\n",
      "Epoch 61/100\n",
      "91073/91073 [==============================] - 0s 4us/sample - loss: 0.0039 - accuracy: 0.9786 - val_loss: 0.0033 - val_accuracy: 0.9798\n",
      "Epoch 62/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0033 - accuracy: 0.9814 - val_loss: 0.0030 - val_accuracy: 0.9793\n",
      "Epoch 63/100\n",
      "91073/91073 [==============================] - 1s 11us/sample - loss: 0.0033 - accuracy: 0.9817 - val_loss: 0.0030 - val_accuracy: 0.9798\n",
      "Epoch 64/100\n",
      "91073/91073 [==============================] - 1s 11us/sample - loss: 0.0032 - accuracy: 0.9819 - val_loss: 0.0027 - val_accuracy: 0.9800\n",
      "Epoch 65/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0031 - accuracy: 0.9824 - val_loss: 0.0033 - val_accuracy: 0.9753\n",
      "Epoch 66/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0031 - accuracy: 0.9823 - val_loss: 0.0037 - val_accuracy: 0.9753\n",
      "Epoch 67/100\n",
      "91073/91073 [==============================] - 1s 13us/sample - loss: 0.0031 - accuracy: 0.9820 - val_loss: 0.0033 - val_accuracy: 0.9760\n",
      "Epoch 68/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0030 - accuracy: 0.9823 - val_loss: 0.0034 - val_accuracy: 0.9777\n",
      "Epoch 69/100\n",
      "91073/91073 [==============================] - 1s 6us/sample - loss: 0.0030 - accuracy: 0.9829 - val_loss: 0.0029 - val_accuracy: 0.9830\n",
      "Epoch 70/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0030 - accuracy: 0.9826 - val_loss: 0.0031 - val_accuracy: 0.9775\n",
      "Epoch 71/100\n",
      "91073/91073 [==============================] - 0s 4us/sample - loss: 0.0029 - accuracy: 0.9829 - val_loss: 0.0032 - val_accuracy: 0.9785\n",
      "Epoch 72/100\n",
      "91073/91073 [==============================] - 0s 4us/sample - loss: 0.0029 - accuracy: 0.9826 - val_loss: 0.0028 - val_accuracy: 0.9798\n",
      "Epoch 73/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0029 - accuracy: 0.9831 - val_loss: 0.0027 - val_accuracy: 0.9808\n",
      "Epoch 74/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0029 - accuracy: 0.9832 - val_loss: 0.0027 - val_accuracy: 0.9814\n",
      "Epoch 75/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0029 - accuracy: 0.9837 - val_loss: 0.0027 - val_accuracy: 0.9809\n",
      "Epoch 76/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0028 - accuracy: 0.9833 - val_loss: 0.0028 - val_accuracy: 0.9817\n",
      "Epoch 77/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0028 - accuracy: 0.9833 - val_loss: 0.0030 - val_accuracy: 0.9783\n",
      "Epoch 78/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0028 - accuracy: 0.9837 - val_loss: 0.0029 - val_accuracy: 0.9823\n",
      "Epoch 79/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0028 - accuracy: 0.9832 - val_loss: 0.0028 - val_accuracy: 0.9827\n",
      "Epoch 80/100\n",
      "91073/91073 [==============================] - 0s 5us/sample - loss: 0.0028 - accuracy: 0.9838 - val_loss: 0.0031 - val_accuracy: 0.9791\n",
      "Epoch 81/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0028 - accuracy: 0.9833 - val_loss: 0.0027 - val_accuracy: 0.9802\n",
      "Epoch 82/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0027 - accuracy: 0.9837 - val_loss: 0.0026 - val_accuracy: 0.9829\n",
      "Epoch 83/100\n",
      "91073/91073 [==============================] - 0s 5us/sample - loss: 0.0027 - accuracy: 0.9836 - val_loss: 0.0028 - val_accuracy: 0.9813\n",
      "Epoch 84/100\n",
      "91073/91073 [==============================] - 1s 11us/sample - loss: 0.0027 - accuracy: 0.9835 - val_loss: 0.0026 - val_accuracy: 0.9794\n",
      "Epoch 85/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0027 - accuracy: 0.9835 - val_loss: 0.0027 - val_accuracy: 0.9818\n",
      "Epoch 86/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0027 - accuracy: 0.9847 - val_loss: 0.0029 - val_accuracy: 0.9813\n",
      "Epoch 87/100\n",
      "91073/91073 [==============================] - 1s 12us/sample - loss: 0.0027 - accuracy: 0.9838 - val_loss: 0.0027 - val_accuracy: 0.9801\n",
      "Epoch 88/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0026 - accuracy: 0.9842 - val_loss: 0.0027 - val_accuracy: 0.9808\n",
      "Epoch 89/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0026 - accuracy: 0.9839 - val_loss: 0.0027 - val_accuracy: 0.9836\n",
      "Epoch 90/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0026 - accuracy: 0.9844 - val_loss: 0.0030 - val_accuracy: 0.9841\n",
      "Epoch 91/100\n",
      "91073/91073 [==============================] - 1s 11us/sample - loss: 0.0026 - accuracy: 0.9843 - val_loss: 0.0023 - val_accuracy: 0.9844\n",
      "Epoch 92/100\n",
      "91073/91073 [==============================] - 1s 12us/sample - loss: 0.0026 - accuracy: 0.9853 - val_loss: 0.0029 - val_accuracy: 0.9765\n",
      "Epoch 93/100\n",
      "91073/91073 [==============================] - 1s 10us/sample - loss: 0.0026 - accuracy: 0.9849 - val_loss: 0.0029 - val_accuracy: 0.9794\n",
      "Epoch 94/100\n",
      "91073/91073 [==============================] - 1s 15us/sample - loss: 0.0026 - accuracy: 0.9847 - val_loss: 0.0030 - val_accuracy: 0.9815\n",
      "Epoch 95/100\n",
      "91073/91073 [==============================] - 1s 12us/sample - loss: 0.0026 - accuracy: 0.9843 - val_loss: 0.0027 - val_accuracy: 0.9795\n",
      "Epoch 96/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0025 - accuracy: 0.9839 - val_loss: 0.0025 - val_accuracy: 0.9821\n",
      "Epoch 97/100\n",
      "91073/91073 [==============================] - 1s 8us/sample - loss: 0.0025 - accuracy: 0.9844 - val_loss: 0.0028 - val_accuracy: 0.9782\n",
      "Epoch 98/100\n",
      "91073/91073 [==============================] - 1s 9us/sample - loss: 0.0025 - accuracy: 0.9845 - val_loss: 0.0026 - val_accuracy: 0.9837\n",
      "Epoch 99/100\n",
      "91073/91073 [==============================] - 1s 6us/sample - loss: 0.0026 - accuracy: 0.9847 - val_loss: 0.0027 - val_accuracy: 0.9851\n",
      "Epoch 100/100\n",
      "91073/91073 [==============================] - 1s 7us/sample - loss: 0.0025 - accuracy: 0.9854 - val_loss: 0.0027 - val_accuracy: 0.9834\n",
      "idx :  2\n",
      "Train on 91074 samples, validate on 22768 samples\n",
      "Epoch 1/100\n",
      "39936/91074 [============>.................] - ETA: 0s - loss: 0.2076 - accuracy: 0.0611"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 13:54:19.770913: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "2022-09-28 13:54:19.770947: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-09-28 13:54:19.770953: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-09-28 13:54:19.774357: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-09-28 13:54:19.774378: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.1496 - accuracy: 0.1754 - val_loss: 0.0917 - val_accuracy: 0.3266\n",
      "Epoch 2/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0735 - accuracy: 0.5184 - val_loss: 0.0628 - val_accuracy: 0.5378\n",
      "Epoch 3/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0512 - accuracy: 0.6694 - val_loss: 0.0474 - val_accuracy: 0.6785\n",
      "Epoch 4/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0393 - accuracy: 0.7551 - val_loss: 0.0369 - val_accuracy: 0.7663\n",
      "Epoch 5/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0325 - accuracy: 0.8123 - val_loss: 0.0309 - val_accuracy: 0.8244\n",
      "Epoch 6/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0286 - accuracy: 0.8406 - val_loss: 0.0265 - val_accuracy: 0.8426\n",
      "Epoch 7/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0225 - accuracy: 0.8715 - val_loss: 0.0181 - val_accuracy: 0.8933\n",
      "Epoch 8/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0170 - accuracy: 0.9067 - val_loss: 0.0152 - val_accuracy: 0.9165\n",
      "Epoch 9/100\n",
      "91074/91074 [==============================] - 0s 5us/sample - loss: 0.0158 - accuracy: 0.9144 - val_loss: 0.0144 - val_accuracy: 0.9160\n",
      "Epoch 10/100\n",
      "91074/91074 [==============================] - 0s 3us/sample - loss: 0.0151 - accuracy: 0.9178 - val_loss: 0.0138 - val_accuracy: 0.9227\n",
      "Epoch 11/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0146 - accuracy: 0.9197 - val_loss: 0.0135 - val_accuracy: 0.9197\n",
      "Epoch 12/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0142 - accuracy: 0.9207 - val_loss: 0.0131 - val_accuracy: 0.9258\n",
      "Epoch 13/100\n",
      "91074/91074 [==============================] - 0s 5us/sample - loss: 0.0138 - accuracy: 0.9222 - val_loss: 0.0128 - val_accuracy: 0.9262\n",
      "Epoch 14/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0135 - accuracy: 0.9239 - val_loss: 0.0124 - val_accuracy: 0.9276\n",
      "Epoch 15/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0131 - accuracy: 0.9266 - val_loss: 0.0120 - val_accuracy: 0.9300\n",
      "Epoch 16/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0123 - accuracy: 0.9334 - val_loss: 0.0108 - val_accuracy: 0.9398\n",
      "Epoch 17/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0110 - accuracy: 0.9415 - val_loss: 0.0098 - val_accuracy: 0.9464\n",
      "Epoch 18/100\n",
      "91074/91074 [==============================] - 0s 5us/sample - loss: 0.0104 - accuracy: 0.9458 - val_loss: 0.0095 - val_accuracy: 0.9487\n",
      "Epoch 19/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0100 - accuracy: 0.9486 - val_loss: 0.0097 - val_accuracy: 0.9512\n",
      "Epoch 20/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0099 - accuracy: 0.9498 - val_loss: 0.0091 - val_accuracy: 0.9534\n",
      "Epoch 21/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0096 - accuracy: 0.9525 - val_loss: 0.0091 - val_accuracy: 0.9502\n",
      "Epoch 22/100\n",
      "91074/91074 [==============================] - 1s 14us/sample - loss: 0.0093 - accuracy: 0.9529 - val_loss: 0.0084 - val_accuracy: 0.9547\n",
      "Epoch 23/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0083 - accuracy: 0.9559 - val_loss: 0.0075 - val_accuracy: 0.9539\n",
      "Epoch 24/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0076 - accuracy: 0.9563 - val_loss: 0.0070 - val_accuracy: 0.9553\n",
      "Epoch 25/100\n",
      "91074/91074 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.95 - 1s 9us/sample - loss: 0.0074 - accuracy: 0.9589 - val_loss: 0.0068 - val_accuracy: 0.9622\n",
      "Epoch 26/100\n",
      "91074/91074 [==============================] - 0s 5us/sample - loss: 0.0074 - accuracy: 0.9603 - val_loss: 0.0071 - val_accuracy: 0.9568\n",
      "Epoch 27/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0070 - accuracy: 0.9619 - val_loss: 0.0069 - val_accuracy: 0.9608\n",
      "Epoch 28/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0070 - accuracy: 0.9626 - val_loss: 0.0065 - val_accuracy: 0.9635\n",
      "Epoch 29/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0071 - accuracy: 0.9608 - val_loss: 0.0070 - val_accuracy: 0.9561\n",
      "Epoch 30/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0068 - accuracy: 0.9633 - val_loss: 0.0067 - val_accuracy: 0.9628\n",
      "Epoch 31/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0070 - accuracy: 0.9620 - val_loss: 0.0065 - val_accuracy: 0.9621\n",
      "Epoch 32/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0069 - accuracy: 0.9646 - val_loss: 0.0063 - val_accuracy: 0.9688\n",
      "Epoch 33/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0071 - accuracy: 0.9614 - val_loss: 0.0063 - val_accuracy: 0.9666\n",
      "Epoch 34/100\n",
      "91074/91074 [==============================] - 0s 4us/sample - loss: 0.0071 - accuracy: 0.9626 - val_loss: 0.0061 - val_accuracy: 0.9700\n",
      "Epoch 35/100\n",
      "91074/91074 [==============================] - 0s 3us/sample - loss: 0.0067 - accuracy: 0.9651 - val_loss: 0.0064 - val_accuracy: 0.9664\n",
      "Epoch 36/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0066 - accuracy: 0.9656 - val_loss: 0.0063 - val_accuracy: 0.9664\n",
      "Epoch 37/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0068 - accuracy: 0.9647 - val_loss: 0.0070 - val_accuracy: 0.9603\n",
      "Epoch 38/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0070 - accuracy: 0.9633 - val_loss: 0.0076 - val_accuracy: 0.9493\n",
      "Epoch 39/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0065 - accuracy: 0.9655 - val_loss: 0.0064 - val_accuracy: 0.9695\n",
      "Epoch 40/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0070 - accuracy: 0.9641 - val_loss: 0.0067 - val_accuracy: 0.9649\n",
      "Epoch 41/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0072 - accuracy: 0.9615 - val_loss: 0.0066 - val_accuracy: 0.9646\n",
      "Epoch 42/100\n",
      "91074/91074 [==============================] - 1s 14us/sample - loss: 0.0064 - accuracy: 0.9675 - val_loss: 0.0062 - val_accuracy: 0.9687\n",
      "Epoch 43/100\n",
      "91074/91074 [==============================] - 1s 13us/sample - loss: 0.0066 - accuracy: 0.9660 - val_loss: 0.0062 - val_accuracy: 0.9661\n",
      "Epoch 44/100\n",
      "91074/91074 [==============================] - 1s 13us/sample - loss: 0.0067 - accuracy: 0.9661 - val_loss: 0.0087 - val_accuracy: 0.9423\n",
      "Epoch 45/100\n",
      "91074/91074 [==============================] - 1s 13us/sample - loss: 0.0065 - accuracy: 0.9668 - val_loss: 0.0061 - val_accuracy: 0.9675\n",
      "Epoch 46/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0066 - accuracy: 0.9669 - val_loss: 0.0068 - val_accuracy: 0.9626\n",
      "Epoch 47/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0063 - accuracy: 0.9680 - val_loss: 0.0061 - val_accuracy: 0.9688\n",
      "Epoch 48/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0065 - accuracy: 0.9672 - val_loss: 0.0059 - val_accuracy: 0.9724\n",
      "Epoch 49/100\n",
      "91074/91074 [==============================] - 0s 5us/sample - loss: 0.0066 - accuracy: 0.9661 - val_loss: 0.0058 - val_accuracy: 0.9724\n",
      "Epoch 50/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0064 - accuracy: 0.9691 - val_loss: 0.0092 - val_accuracy: 0.9595\n",
      "Epoch 51/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0067 - accuracy: 0.9667 - val_loss: 0.0059 - val_accuracy: 0.9695\n",
      "Epoch 52/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0068 - accuracy: 0.9657 - val_loss: 0.0062 - val_accuracy: 0.9707\n",
      "Epoch 53/100\n",
      "91074/91074 [==============================] - 0s 5us/sample - loss: 0.0063 - accuracy: 0.9682 - val_loss: 0.0058 - val_accuracy: 0.9709\n",
      "Epoch 54/100\n",
      "91074/91074 [==============================] - 1s 13us/sample - loss: 0.0067 - accuracy: 0.9667 - val_loss: 0.0059 - val_accuracy: 0.9696\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0062 - accuracy: 0.9693 - val_loss: 0.0061 - val_accuracy: 0.9690\n",
      "Epoch 56/100\n",
      "91074/91074 [==============================] - 1s 15us/sample - loss: 0.0069 - accuracy: 0.9657 - val_loss: 0.0068 - val_accuracy: 0.9689\n",
      "Epoch 57/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0064 - accuracy: 0.9686 - val_loss: 0.0058 - val_accuracy: 0.9724\n",
      "Epoch 58/100\n",
      "91074/91074 [==============================] - 0s 5us/sample - loss: 0.0063 - accuracy: 0.9697 - val_loss: 0.0061 - val_accuracy: 0.9682\n",
      "Epoch 59/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0065 - accuracy: 0.9672 - val_loss: 0.0066 - val_accuracy: 0.9678\n",
      "Epoch 60/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0065 - accuracy: 0.9686 - val_loss: 0.0067 - val_accuracy: 0.9671\n",
      "Epoch 61/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0063 - accuracy: 0.9703 - val_loss: 0.0055 - val_accuracy: 0.9745\n",
      "Epoch 62/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0065 - accuracy: 0.9673 - val_loss: 0.0059 - val_accuracy: 0.9714\n",
      "Epoch 63/100\n",
      "91074/91074 [==============================] - 1s 13us/sample - loss: 0.0063 - accuracy: 0.9696 - val_loss: 0.0068 - val_accuracy: 0.9656\n",
      "Epoch 64/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0065 - accuracy: 0.9684 - val_loss: 0.0059 - val_accuracy: 0.9703\n",
      "Epoch 65/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0063 - accuracy: 0.9691 - val_loss: 0.0083 - val_accuracy: 0.9565\n",
      "Epoch 66/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0066 - accuracy: 0.9658 - val_loss: 0.0064 - val_accuracy: 0.9683\n",
      "Epoch 67/100\n",
      "91074/91074 [==============================] - 1s 13us/sample - loss: 0.0067 - accuracy: 0.9664 - val_loss: 0.0061 - val_accuracy: 0.9715\n",
      "Epoch 68/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0063 - accuracy: 0.9692 - val_loss: 0.0071 - val_accuracy: 0.9613\n",
      "Epoch 69/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0067 - accuracy: 0.9680 - val_loss: 0.0061 - val_accuracy: 0.9736\n",
      "Epoch 70/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0063 - accuracy: 0.9693 - val_loss: 0.0055 - val_accuracy: 0.9759\n",
      "Epoch 71/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0062 - accuracy: 0.9700 - val_loss: 0.0061 - val_accuracy: 0.9726\n",
      "Epoch 72/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0067 - accuracy: 0.9675 - val_loss: 0.0070 - val_accuracy: 0.9563\n",
      "Epoch 73/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0062 - accuracy: 0.9698 - val_loss: 0.0054 - val_accuracy: 0.9747\n",
      "Epoch 74/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0062 - accuracy: 0.9684 - val_loss: 0.0052 - val_accuracy: 0.9732\n",
      "Epoch 75/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0060 - accuracy: 0.9710 - val_loss: 0.0069 - val_accuracy: 0.9618\n",
      "Epoch 76/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0056 - accuracy: 0.9749 - val_loss: 0.0065 - val_accuracy: 0.9711\n",
      "Epoch 77/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0056 - accuracy: 0.9746 - val_loss: 0.0098 - val_accuracy: 0.9495\n",
      "Epoch 78/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0057 - accuracy: 0.9726 - val_loss: 0.0067 - val_accuracy: 0.9701\n",
      "Epoch 79/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0056 - accuracy: 0.9721 - val_loss: 0.0051 - val_accuracy: 0.9769\n",
      "Epoch 80/100\n",
      "91074/91074 [==============================] - 0s 5us/sample - loss: 0.0052 - accuracy: 0.9757 - val_loss: 0.0056 - val_accuracy: 0.9751\n",
      "Epoch 81/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0052 - accuracy: 0.9751 - val_loss: 0.0050 - val_accuracy: 0.9778\n",
      "Epoch 82/100\n",
      "91074/91074 [==============================] - 0s 5us/sample - loss: 0.0054 - accuracy: 0.9733 - val_loss: 0.0061 - val_accuracy: 0.9796\n",
      "Epoch 83/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0054 - accuracy: 0.9745 - val_loss: 0.0052 - val_accuracy: 0.9765\n",
      "Epoch 84/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0055 - accuracy: 0.9733 - val_loss: 0.0060 - val_accuracy: 0.9730\n",
      "Epoch 85/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0056 - accuracy: 0.9745 - val_loss: 0.0075 - val_accuracy: 0.9652\n",
      "Epoch 86/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0061 - accuracy: 0.9718 - val_loss: 0.0068 - val_accuracy: 0.9739\n",
      "Epoch 87/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0052 - accuracy: 0.9753 - val_loss: 0.0047 - val_accuracy: 0.9765\n",
      "Epoch 88/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0054 - accuracy: 0.9748 - val_loss: 0.0045 - val_accuracy: 0.9805\n",
      "Epoch 89/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0056 - accuracy: 0.9727 - val_loss: 0.0047 - val_accuracy: 0.9785\n",
      "Epoch 90/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0054 - accuracy: 0.9723 - val_loss: 0.0052 - val_accuracy: 0.9762\n",
      "Epoch 91/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0054 - accuracy: 0.9743 - val_loss: 0.0056 - val_accuracy: 0.9748\n",
      "Epoch 92/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0056 - accuracy: 0.9733 - val_loss: 0.0050 - val_accuracy: 0.9751\n",
      "Epoch 93/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0055 - accuracy: 0.9740 - val_loss: 0.0059 - val_accuracy: 0.9633\n",
      "Epoch 94/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0055 - accuracy: 0.9715 - val_loss: 0.0057 - val_accuracy: 0.9718\n",
      "Epoch 95/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0051 - accuracy: 0.9769 - val_loss: 0.0052 - val_accuracy: 0.9773\n",
      "Epoch 96/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0056 - accuracy: 0.9750 - val_loss: 0.0055 - val_accuracy: 0.9754\n",
      "Epoch 97/100\n",
      "91074/91074 [==============================] - 0s 5us/sample - loss: 0.0051 - accuracy: 0.9769 - val_loss: 0.0043 - val_accuracy: 0.9853\n",
      "Epoch 98/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0053 - accuracy: 0.9769 - val_loss: 0.0061 - val_accuracy: 0.9690\n",
      "Epoch 99/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0052 - accuracy: 0.9754 - val_loss: 0.0064 - val_accuracy: 0.9633\n",
      "Epoch 100/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0052 - accuracy: 0.9765 - val_loss: 0.0050 - val_accuracy: 0.9794\n",
      "idx :  3\n",
      "Train on 91074 samples, validate on 22768 samples\n",
      "Epoch 1/100\n",
      "39424/91074 [===========>..................] - ETA: 0s - loss: 0.2154 - accuracy: 0.0897"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 13:55:40.702272: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "2022-09-28 13:55:40.702308: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-09-28 13:55:40.702314: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-09-28 13:55:40.705576: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-09-28 13:55:40.705615: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.1528 - accuracy: 0.1774 - val_loss: 0.0895 - val_accuracy: 0.4754\n",
      "Epoch 2/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0722 - accuracy: 0.4991 - val_loss: 0.0555 - val_accuracy: 0.6754\n",
      "Epoch 3/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0463 - accuracy: 0.7062 - val_loss: 0.0397 - val_accuracy: 0.7663\n",
      "Epoch 4/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0339 - accuracy: 0.7867 - val_loss: 0.0308 - val_accuracy: 0.8223\n",
      "Epoch 5/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0268 - accuracy: 0.8413 - val_loss: 0.0252 - val_accuracy: 0.8638\n",
      "Epoch 6/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0220 - accuracy: 0.8696 - val_loss: 0.0216 - val_accuracy: 0.8771\n",
      "Epoch 7/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0195 - accuracy: 0.8879 - val_loss: 0.0200 - val_accuracy: 0.8912\n",
      "Epoch 8/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0182 - accuracy: 0.8993 - val_loss: 0.0190 - val_accuracy: 0.8970\n",
      "Epoch 9/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0173 - accuracy: 0.9052 - val_loss: 0.0181 - val_accuracy: 0.9075\n",
      "Epoch 10/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0167 - accuracy: 0.9090 - val_loss: 0.0175 - val_accuracy: 0.9104\n",
      "Epoch 11/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0163 - accuracy: 0.9131 - val_loss: 0.0170 - val_accuracy: 0.9130\n",
      "Epoch 12/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0159 - accuracy: 0.9156 - val_loss: 0.0168 - val_accuracy: 0.9145\n",
      "Epoch 13/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0157 - accuracy: 0.9186 - val_loss: 0.0165 - val_accuracy: 0.9188\n",
      "Epoch 14/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0154 - accuracy: 0.9214 - val_loss: 0.0168 - val_accuracy: 0.9156\n",
      "Epoch 15/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0153 - accuracy: 0.9219 - val_loss: 0.0161 - val_accuracy: 0.9234\n",
      "Epoch 16/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0151 - accuracy: 0.9237 - val_loss: 0.0162 - val_accuracy: 0.9141\n",
      "Epoch 17/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0150 - accuracy: 0.9248 - val_loss: 0.0159 - val_accuracy: 0.9231\n",
      "Epoch 18/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0149 - accuracy: 0.9259 - val_loss: 0.0158 - val_accuracy: 0.9234\n",
      "Epoch 19/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0148 - accuracy: 0.9275 - val_loss: 0.0157 - val_accuracy: 0.9230\n",
      "Epoch 20/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0144 - accuracy: 0.9292 - val_loss: 0.0145 - val_accuracy: 0.9318\n",
      "Epoch 21/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0126 - accuracy: 0.9410 - val_loss: 0.0121 - val_accuracy: 0.9450\n",
      "Epoch 22/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0117 - accuracy: 0.9439 - val_loss: 0.0119 - val_accuracy: 0.9460\n",
      "Epoch 23/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0115 - accuracy: 0.9466 - val_loss: 0.0122 - val_accuracy: 0.9413\n",
      "Epoch 24/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0114 - accuracy: 0.9471 - val_loss: 0.0119 - val_accuracy: 0.9461\n",
      "Epoch 25/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0114 - accuracy: 0.9460 - val_loss: 0.0119 - val_accuracy: 0.9453\n",
      "Epoch 26/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0114 - accuracy: 0.9475 - val_loss: 0.0122 - val_accuracy: 0.9462\n",
      "Epoch 27/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0113 - accuracy: 0.9481 - val_loss: 0.0119 - val_accuracy: 0.9443\n",
      "Epoch 28/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0113 - accuracy: 0.9485 - val_loss: 0.0118 - val_accuracy: 0.9483\n",
      "Epoch 29/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0112 - accuracy: 0.9486 - val_loss: 0.0116 - val_accuracy: 0.9509\n",
      "Epoch 30/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0112 - accuracy: 0.9496 - val_loss: 0.0114 - val_accuracy: 0.9506\n",
      "Epoch 31/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0112 - accuracy: 0.9497 - val_loss: 0.0115 - val_accuracy: 0.9500\n",
      "Epoch 32/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0110 - accuracy: 0.9516 - val_loss: 0.0116 - val_accuracy: 0.9480\n",
      "Epoch 33/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0109 - accuracy: 0.9503 - val_loss: 0.0114 - val_accuracy: 0.9495\n",
      "Epoch 34/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0108 - accuracy: 0.9523 - val_loss: 0.0110 - val_accuracy: 0.9535\n",
      "Epoch 35/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0106 - accuracy: 0.9538 - val_loss: 0.0108 - val_accuracy: 0.9534\n",
      "Epoch 36/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0104 - accuracy: 0.9553 - val_loss: 0.0108 - val_accuracy: 0.9515\n",
      "Epoch 37/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0102 - accuracy: 0.9563 - val_loss: 0.0109 - val_accuracy: 0.9498\n",
      "Epoch 38/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0100 - accuracy: 0.9578 - val_loss: 0.0106 - val_accuracy: 0.9520\n",
      "Epoch 39/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0098 - accuracy: 0.9587 - val_loss: 0.0102 - val_accuracy: 0.9547\n",
      "Epoch 40/100\n",
      "91074/91074 [==============================] - 0s 5us/sample - loss: 0.0099 - accuracy: 0.9565 - val_loss: 0.0100 - val_accuracy: 0.9584\n",
      "Epoch 41/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0096 - accuracy: 0.9598 - val_loss: 0.0098 - val_accuracy: 0.9581\n",
      "Epoch 42/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0096 - accuracy: 0.9594 - val_loss: 0.0098 - val_accuracy: 0.9572\n",
      "Epoch 43/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0096 - accuracy: 0.9592 - val_loss: 0.0100 - val_accuracy: 0.9524\n",
      "Epoch 44/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0096 - accuracy: 0.9590 - val_loss: 0.0096 - val_accuracy: 0.9569\n",
      "Epoch 45/100\n",
      "91074/91074 [==============================] - 0s 4us/sample - loss: 0.0094 - accuracy: 0.9602 - val_loss: 0.0095 - val_accuracy: 0.9588\n",
      "Epoch 46/100\n",
      "91074/91074 [==============================] - 0s 4us/sample - loss: 0.0094 - accuracy: 0.9597 - val_loss: 0.0094 - val_accuracy: 0.9603\n",
      "Epoch 47/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0094 - accuracy: 0.9611 - val_loss: 0.0093 - val_accuracy: 0.9605\n",
      "Epoch 48/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0093 - accuracy: 0.9601 - val_loss: 0.0094 - val_accuracy: 0.9584\n",
      "Epoch 49/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0094 - accuracy: 0.9596 - val_loss: 0.0093 - val_accuracy: 0.9609\n",
      "Epoch 50/100\n",
      "91074/91074 [==============================] - 0s 4us/sample - loss: 0.0092 - accuracy: 0.9625 - val_loss: 0.0095 - val_accuracy: 0.9585\n",
      "Epoch 51/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0092 - accuracy: 0.9614 - val_loss: 0.0093 - val_accuracy: 0.9608\n",
      "Epoch 52/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0093 - accuracy: 0.9607 - val_loss: 0.0094 - val_accuracy: 0.9581\n",
      "Epoch 53/100\n",
      "91074/91074 [==============================] - 0s 4us/sample - loss: 0.0092 - accuracy: 0.9605 - val_loss: 0.0093 - val_accuracy: 0.9607\n",
      "Epoch 54/100\n",
      "91074/91074 [==============================] - 0s 4us/sample - loss: 0.0092 - accuracy: 0.9614 - val_loss: 0.0093 - val_accuracy: 0.9597\n",
      "Epoch 55/100\n",
      "91074/91074 [==============================] - 0s 5us/sample - loss: 0.0092 - accuracy: 0.9605 - val_loss: 0.0092 - val_accuracy: 0.9624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0091 - accuracy: 0.9625 - val_loss: 0.0096 - val_accuracy: 0.9584\n",
      "Epoch 57/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0092 - accuracy: 0.9619 - val_loss: 0.0092 - val_accuracy: 0.9617\n",
      "Epoch 58/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0092 - accuracy: 0.9620 - val_loss: 0.0091 - val_accuracy: 0.9623\n",
      "Epoch 59/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0090 - accuracy: 0.9628 - val_loss: 0.0092 - val_accuracy: 0.9613\n",
      "Epoch 60/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0091 - accuracy: 0.9628 - val_loss: 0.0093 - val_accuracy: 0.9600\n",
      "Epoch 61/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0091 - accuracy: 0.9609 - val_loss: 0.0092 - val_accuracy: 0.9604\n",
      "Epoch 62/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0091 - accuracy: 0.9620 - val_loss: 0.0093 - val_accuracy: 0.9591\n",
      "Epoch 63/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0091 - accuracy: 0.9620 - val_loss: 0.0093 - val_accuracy: 0.9620\n",
      "Epoch 64/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0091 - accuracy: 0.9626 - val_loss: 0.0092 - val_accuracy: 0.9627\n",
      "Epoch 65/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0091 - accuracy: 0.9619 - val_loss: 0.0091 - val_accuracy: 0.9621\n",
      "Epoch 66/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0089 - accuracy: 0.9642 - val_loss: 0.0091 - val_accuracy: 0.9622\n",
      "Epoch 67/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0090 - accuracy: 0.9626 - val_loss: 0.0091 - val_accuracy: 0.9626\n",
      "Epoch 68/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0090 - accuracy: 0.9626 - val_loss: 0.0095 - val_accuracy: 0.9587\n",
      "Epoch 69/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0091 - accuracy: 0.9628 - val_loss: 0.0096 - val_accuracy: 0.9575\n",
      "Epoch 70/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0091 - accuracy: 0.9621 - val_loss: 0.0093 - val_accuracy: 0.9622\n",
      "Epoch 71/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0091 - accuracy: 0.9621 - val_loss: 0.0116 - val_accuracy: 0.9564\n",
      "Epoch 72/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0089 - accuracy: 0.9635 - val_loss: 0.0088 - val_accuracy: 0.9638\n",
      "Epoch 73/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0084 - accuracy: 0.9636 - val_loss: 0.0077 - val_accuracy: 0.9671\n",
      "Epoch 74/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0077 - accuracy: 0.9653 - val_loss: 0.0069 - val_accuracy: 0.9689\n",
      "Epoch 75/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0072 - accuracy: 0.9669 - val_loss: 0.0076 - val_accuracy: 0.9659\n",
      "Epoch 76/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0072 - accuracy: 0.9672 - val_loss: 0.0071 - val_accuracy: 0.9680\n",
      "Epoch 77/100\n",
      "91074/91074 [==============================] - 1s 13us/sample - loss: 0.0072 - accuracy: 0.9670 - val_loss: 0.0077 - val_accuracy: 0.9610\n",
      "Epoch 78/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0070 - accuracy: 0.9689 - val_loss: 0.0068 - val_accuracy: 0.9693\n",
      "Epoch 79/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0072 - accuracy: 0.9661 - val_loss: 0.0068 - val_accuracy: 0.9672\n",
      "Epoch 80/100\n",
      "91074/91074 [==============================] - 1s 13us/sample - loss: 0.0073 - accuracy: 0.9656 - val_loss: 0.0069 - val_accuracy: 0.9695\n",
      "Epoch 81/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0071 - accuracy: 0.9673 - val_loss: 0.0066 - val_accuracy: 0.9697\n",
      "Epoch 82/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0073 - accuracy: 0.9649 - val_loss: 0.0066 - val_accuracy: 0.9683\n",
      "Epoch 83/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0071 - accuracy: 0.9675 - val_loss: 0.0083 - val_accuracy: 0.9588\n",
      "Epoch 84/100\n",
      "91074/91074 [==============================] - 1s 13us/sample - loss: 0.0071 - accuracy: 0.9672 - val_loss: 0.0065 - val_accuracy: 0.9700\n",
      "Epoch 85/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0070 - accuracy: 0.9684 - val_loss: 0.0073 - val_accuracy: 0.9611\n",
      "Epoch 86/100\n",
      "91074/91074 [==============================] - 1s 14us/sample - loss: 0.0070 - accuracy: 0.9678 - val_loss: 0.0068 - val_accuracy: 0.9675\n",
      "Epoch 87/100\n",
      "91074/91074 [==============================] - 1s 13us/sample - loss: 0.0070 - accuracy: 0.9678 - val_loss: 0.0065 - val_accuracy: 0.9709\n",
      "Epoch 88/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0069 - accuracy: 0.9675 - val_loss: 0.0064 - val_accuracy: 0.9706\n",
      "Epoch 89/100\n",
      "91074/91074 [==============================] - 0s 3us/sample - loss: 0.0070 - accuracy: 0.9684 - val_loss: 0.0068 - val_accuracy: 0.9670\n",
      "Epoch 90/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0070 - accuracy: 0.9683 - val_loss: 0.0065 - val_accuracy: 0.9711\n",
      "Epoch 91/100\n",
      "91074/91074 [==============================] - 1s 14us/sample - loss: 0.0069 - accuracy: 0.9699 - val_loss: 0.0063 - val_accuracy: 0.9689\n",
      "Epoch 92/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0067 - accuracy: 0.9707 - val_loss: 0.0062 - val_accuracy: 0.9721\n",
      "Epoch 93/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0066 - accuracy: 0.9701 - val_loss: 0.0060 - val_accuracy: 0.9686\n",
      "Epoch 94/100\n",
      "91074/91074 [==============================] - 0s 5us/sample - loss: 0.0067 - accuracy: 0.9689 - val_loss: 0.0082 - val_accuracy: 0.9612\n",
      "Epoch 95/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0061 - accuracy: 0.9729 - val_loss: 0.0053 - val_accuracy: 0.9754\n",
      "Epoch 96/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0062 - accuracy: 0.9730 - val_loss: 0.0057 - val_accuracy: 0.9746\n",
      "Epoch 97/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0064 - accuracy: 0.9728 - val_loss: 0.0054 - val_accuracy: 0.9772\n",
      "Epoch 98/100\n",
      "91074/91074 [==============================] - 1s 13us/sample - loss: 0.0061 - accuracy: 0.9744 - val_loss: 0.0060 - val_accuracy: 0.9733\n",
      "Epoch 99/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0066 - accuracy: 0.9710 - val_loss: 0.0057 - val_accuracy: 0.9762\n",
      "Epoch 100/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0063 - accuracy: 0.9732 - val_loss: 0.0051 - val_accuracy: 0.9786\n",
      "idx :  4\n",
      "Train on 91074 samples, validate on 22768 samples\n",
      "Epoch 1/100\n",
      "46592/91074 [==============>...............] - ETA: 0s - loss: 0.2037 - accuracy: 0.0718"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 13:56:57.336189: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
      "2022-09-28 13:56:57.336223: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-09-28 13:56:57.336229: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-09-28 13:56:57.339575: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-09-28 13:56:57.339597: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.1535 - accuracy: 0.1896 - val_loss: 0.0959 - val_accuracy: 0.4720\n",
      "Epoch 2/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0704 - accuracy: 0.5173 - val_loss: 0.0613 - val_accuracy: 0.6122\n",
      "Epoch 3/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0472 - accuracy: 0.7065 - val_loss: 0.0416 - val_accuracy: 0.7546\n",
      "Epoch 4/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0337 - accuracy: 0.8069 - val_loss: 0.0300 - val_accuracy: 0.8217\n",
      "Epoch 5/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0251 - accuracy: 0.8591 - val_loss: 0.0230 - val_accuracy: 0.8613\n",
      "Epoch 6/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0198 - accuracy: 0.8873 - val_loss: 0.0178 - val_accuracy: 0.9116\n",
      "Epoch 7/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0171 - accuracy: 0.9076 - val_loss: 0.0160 - val_accuracy: 0.9219\n",
      "Epoch 8/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0156 - accuracy: 0.9204 - val_loss: 0.0144 - val_accuracy: 0.9398\n",
      "Epoch 9/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0134 - accuracy: 0.9311 - val_loss: 0.0117 - val_accuracy: 0.9477\n",
      "Epoch 10/100\n",
      "91074/91074 [==============================] - 0s 4us/sample - loss: 0.0112 - accuracy: 0.9410 - val_loss: 0.0102 - val_accuracy: 0.9480\n",
      "Epoch 11/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0104 - accuracy: 0.9461 - val_loss: 0.0107 - val_accuracy: 0.9433\n",
      "Epoch 12/100\n",
      "91074/91074 [==============================] - 1s 13us/sample - loss: 0.0100 - accuracy: 0.9494 - val_loss: 0.0103 - val_accuracy: 0.9516\n",
      "Epoch 13/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0099 - accuracy: 0.9504 - val_loss: 0.0092 - val_accuracy: 0.9572\n",
      "Epoch 14/100\n",
      "91074/91074 [==============================] - 0s 4us/sample - loss: 0.0097 - accuracy: 0.9501 - val_loss: 0.0095 - val_accuracy: 0.9536\n",
      "Epoch 15/100\n",
      "91074/91074 [==============================] - 1s 13us/sample - loss: 0.0093 - accuracy: 0.9511 - val_loss: 0.0086 - val_accuracy: 0.9534\n",
      "Epoch 16/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0086 - accuracy: 0.9531 - val_loss: 0.0089 - val_accuracy: 0.9516\n",
      "Epoch 17/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0081 - accuracy: 0.9547 - val_loss: 0.0072 - val_accuracy: 0.9617\n",
      "Epoch 18/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0081 - accuracy: 0.9520 - val_loss: 0.0091 - val_accuracy: 0.9397\n",
      "Epoch 19/100\n",
      "91074/91074 [==============================] - 0s 5us/sample - loss: 0.0079 - accuracy: 0.9548 - val_loss: 0.0069 - val_accuracy: 0.9641\n",
      "Epoch 20/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0073 - accuracy: 0.9590 - val_loss: 0.0074 - val_accuracy: 0.9608\n",
      "Epoch 21/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0069 - accuracy: 0.9612 - val_loss: 0.0061 - val_accuracy: 0.9684\n",
      "Epoch 22/100\n",
      "91074/91074 [==============================] - 0s 4us/sample - loss: 0.0073 - accuracy: 0.9577 - val_loss: 0.0071 - val_accuracy: 0.9593\n",
      "Epoch 23/100\n",
      "91074/91074 [==============================] - 1s 13us/sample - loss: 0.0068 - accuracy: 0.9635 - val_loss: 0.0057 - val_accuracy: 0.9723\n",
      "Epoch 24/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0070 - accuracy: 0.9606 - val_loss: 0.0084 - val_accuracy: 0.9633\n",
      "Epoch 25/100\n",
      "91074/91074 [==============================] - 1s 14us/sample - loss: 0.0066 - accuracy: 0.9632 - val_loss: 0.0095 - val_accuracy: 0.9379\n",
      "Epoch 26/100\n",
      "91074/91074 [==============================] - 0s 4us/sample - loss: 0.0070 - accuracy: 0.9617 - val_loss: 0.0051 - val_accuracy: 0.9710\n",
      "Epoch 27/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0062 - accuracy: 0.9670 - val_loss: 0.0058 - val_accuracy: 0.9662\n",
      "Epoch 28/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0062 - accuracy: 0.9672 - val_loss: 0.0057 - val_accuracy: 0.9694\n",
      "Epoch 29/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0063 - accuracy: 0.9668 - val_loss: 0.0071 - val_accuracy: 0.9669\n",
      "Epoch 30/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0064 - accuracy: 0.9654 - val_loss: 0.0068 - val_accuracy: 0.9652\n",
      "Epoch 31/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0064 - accuracy: 0.9653 - val_loss: 0.0051 - val_accuracy: 0.9750\n",
      "Epoch 32/100\n",
      "91074/91074 [==============================] - 0s 4us/sample - loss: 0.0061 - accuracy: 0.9679 - val_loss: 0.0058 - val_accuracy: 0.9673\n",
      "Epoch 33/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0064 - accuracy: 0.9666 - val_loss: 0.0071 - val_accuracy: 0.9657\n",
      "Epoch 34/100\n",
      "91074/91074 [==============================] - 0s 3us/sample - loss: 0.0063 - accuracy: 0.9673 - val_loss: 0.0054 - val_accuracy: 0.9744\n",
      "Epoch 35/100\n",
      "91074/91074 [==============================] - 0s 5us/sample - loss: 0.0061 - accuracy: 0.9666 - val_loss: 0.0056 - val_accuracy: 0.9721\n",
      "Epoch 36/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0061 - accuracy: 0.9699 - val_loss: 0.0053 - val_accuracy: 0.9755\n",
      "Epoch 37/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0061 - accuracy: 0.9675 - val_loss: 0.0056 - val_accuracy: 0.9735\n",
      "Epoch 38/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0063 - accuracy: 0.9672 - val_loss: 0.0067 - val_accuracy: 0.9697\n",
      "Epoch 39/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0059 - accuracy: 0.9696 - val_loss: 0.0065 - val_accuracy: 0.9758\n",
      "Epoch 40/100\n",
      "91074/91074 [==============================] - 0s 5us/sample - loss: 0.0062 - accuracy: 0.9675 - val_loss: 0.0050 - val_accuracy: 0.9726\n",
      "Epoch 41/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0063 - accuracy: 0.9676 - val_loss: 0.0065 - val_accuracy: 0.9626\n",
      "Epoch 42/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0059 - accuracy: 0.9710 - val_loss: 0.0050 - val_accuracy: 0.9785\n",
      "Epoch 43/100\n",
      "91074/91074 [==============================] - 1s 13us/sample - loss: 0.0058 - accuracy: 0.9707 - val_loss: 0.0053 - val_accuracy: 0.9793\n",
      "Epoch 44/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0062 - accuracy: 0.9710 - val_loss: 0.0052 - val_accuracy: 0.9794\n",
      "Epoch 45/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0061 - accuracy: 0.9681 - val_loss: 0.0066 - val_accuracy: 0.9631\n",
      "Epoch 46/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0063 - accuracy: 0.9676 - val_loss: 0.0056 - val_accuracy: 0.9766\n",
      "Epoch 47/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0060 - accuracy: 0.9688 - val_loss: 0.0053 - val_accuracy: 0.9799\n",
      "Epoch 48/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0061 - accuracy: 0.9684 - val_loss: 0.0097 - val_accuracy: 0.9478\n",
      "Epoch 49/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0062 - accuracy: 0.9697 - val_loss: 0.0044 - val_accuracy: 0.9804\n",
      "Epoch 50/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0060 - accuracy: 0.9692 - val_loss: 0.0046 - val_accuracy: 0.9771\n",
      "Epoch 51/100\n",
      "91074/91074 [==============================] - 1s 14us/sample - loss: 0.0059 - accuracy: 0.9701 - val_loss: 0.0080 - val_accuracy: 0.9664\n",
      "Epoch 52/100\n",
      "91074/91074 [==============================] - 0s 5us/sample - loss: 0.0059 - accuracy: 0.9710 - val_loss: 0.0046 - val_accuracy: 0.9753\n",
      "Epoch 53/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0056 - accuracy: 0.9729 - val_loss: 0.0047 - val_accuracy: 0.9822\n",
      "Epoch 54/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0057 - accuracy: 0.9716 - val_loss: 0.0049 - val_accuracy: 0.9803\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0061 - accuracy: 0.9707 - val_loss: 0.0070 - val_accuracy: 0.9619\n",
      "Epoch 56/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0057 - accuracy: 0.9712 - val_loss: 0.0052 - val_accuracy: 0.9710\n",
      "Epoch 57/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0060 - accuracy: 0.9706 - val_loss: 0.0059 - val_accuracy: 0.9720\n",
      "Epoch 58/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0062 - accuracy: 0.9708 - val_loss: 0.0053 - val_accuracy: 0.9751\n",
      "Epoch 59/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0056 - accuracy: 0.9730 - val_loss: 0.0051 - val_accuracy: 0.9762\n",
      "Epoch 60/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0059 - accuracy: 0.9704 - val_loss: 0.0056 - val_accuracy: 0.9743\n",
      "Epoch 61/100\n",
      "91074/91074 [==============================] - 1s 14us/sample - loss: 0.0057 - accuracy: 0.9716 - val_loss: 0.0062 - val_accuracy: 0.9670\n",
      "Epoch 62/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0058 - accuracy: 0.9711 - val_loss: 0.0054 - val_accuracy: 0.9745\n",
      "Epoch 63/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0057 - accuracy: 0.9722 - val_loss: 0.0049 - val_accuracy: 0.9794\n",
      "Epoch 64/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0056 - accuracy: 0.9700 - val_loss: 0.0049 - val_accuracy: 0.9798\n",
      "Epoch 65/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0057 - accuracy: 0.9720 - val_loss: 0.0071 - val_accuracy: 0.9802\n",
      "Epoch 66/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0059 - accuracy: 0.9717 - val_loss: 0.0059 - val_accuracy: 0.9819\n",
      "Epoch 67/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0058 - accuracy: 0.9706 - val_loss: 0.0050 - val_accuracy: 0.9780\n",
      "Epoch 68/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0057 - accuracy: 0.9707 - val_loss: 0.0067 - val_accuracy: 0.9705\n",
      "Epoch 69/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0063 - accuracy: 0.9703 - val_loss: 0.0043 - val_accuracy: 0.9822\n",
      "Epoch 70/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0059 - accuracy: 0.9715 - val_loss: 0.0045 - val_accuracy: 0.9790\n",
      "Epoch 71/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0056 - accuracy: 0.9715 - val_loss: 0.0053 - val_accuracy: 0.9751\n",
      "Epoch 72/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0057 - accuracy: 0.9748 - val_loss: 0.0051 - val_accuracy: 0.9752\n",
      "Epoch 73/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0060 - accuracy: 0.9695 - val_loss: 0.0064 - val_accuracy: 0.9753\n",
      "Epoch 74/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0058 - accuracy: 0.9720 - val_loss: 0.0061 - val_accuracy: 0.9756\n",
      "Epoch 75/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0059 - accuracy: 0.9695 - val_loss: 0.0051 - val_accuracy: 0.9739\n",
      "Epoch 76/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0057 - accuracy: 0.9702 - val_loss: 0.0054 - val_accuracy: 0.9732\n",
      "Epoch 77/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0057 - accuracy: 0.9737 - val_loss: 0.0064 - val_accuracy: 0.9763\n",
      "Epoch 78/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0059 - accuracy: 0.9714 - val_loss: 0.0039 - val_accuracy: 0.9825\n",
      "Epoch 79/100\n",
      "91074/91074 [==============================] - 1s 7us/sample - loss: 0.0059 - accuracy: 0.9698 - val_loss: 0.0045 - val_accuracy: 0.9811\n",
      "Epoch 80/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0055 - accuracy: 0.9737 - val_loss: 0.0054 - val_accuracy: 0.9767\n",
      "Epoch 81/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0055 - accuracy: 0.9737 - val_loss: 0.0064 - val_accuracy: 0.9738\n",
      "Epoch 82/100\n",
      "91074/91074 [==============================] - 1s 10us/sample - loss: 0.0055 - accuracy: 0.9740 - val_loss: 0.0079 - val_accuracy: 0.9714\n",
      "Epoch 83/100\n",
      "91074/91074 [==============================] - 0s 5us/sample - loss: 0.0058 - accuracy: 0.9734 - val_loss: 0.0053 - val_accuracy: 0.9729\n",
      "Epoch 84/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0057 - accuracy: 0.9698 - val_loss: 0.0055 - val_accuracy: 0.9624\n",
      "Epoch 85/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0059 - accuracy: 0.9714 - val_loss: 0.0040 - val_accuracy: 0.9821\n",
      "Epoch 86/100\n",
      "91074/91074 [==============================] - 1s 8us/sample - loss: 0.0058 - accuracy: 0.9723 - val_loss: 0.0046 - val_accuracy: 0.9744\n",
      "Epoch 87/100\n",
      "91074/91074 [==============================] - 1s 13us/sample - loss: 0.0055 - accuracy: 0.9735 - val_loss: 0.0065 - val_accuracy: 0.9700\n",
      "Epoch 88/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0057 - accuracy: 0.9729 - val_loss: 0.0061 - val_accuracy: 0.9730\n",
      "Epoch 89/100\n",
      "91074/91074 [==============================] - 1s 13us/sample - loss: 0.0056 - accuracy: 0.9731 - val_loss: 0.0062 - val_accuracy: 0.9787\n",
      "Epoch 90/100\n",
      "91074/91074 [==============================] - 1s 9us/sample - loss: 0.0057 - accuracy: 0.9754 - val_loss: 0.0046 - val_accuracy: 0.9793\n",
      "Epoch 91/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0059 - accuracy: 0.9732 - val_loss: 0.0058 - val_accuracy: 0.9670\n",
      "Epoch 92/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0054 - accuracy: 0.9728 - val_loss: 0.0052 - val_accuracy: 0.9798\n",
      "Epoch 93/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0055 - accuracy: 0.9728 - val_loss: 0.0048 - val_accuracy: 0.9722\n",
      "Epoch 94/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0053 - accuracy: 0.9758 - val_loss: 0.0053 - val_accuracy: 0.9832\n",
      "Epoch 95/100\n",
      "91074/91074 [==============================] - 1s 13us/sample - loss: 0.0055 - accuracy: 0.9731 - val_loss: 0.0055 - val_accuracy: 0.9744\n",
      "Epoch 96/100\n",
      "91074/91074 [==============================] - 1s 13us/sample - loss: 0.0054 - accuracy: 0.9734 - val_loss: 0.0047 - val_accuracy: 0.9801\n",
      "Epoch 97/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0056 - accuracy: 0.9741 - val_loss: 0.0047 - val_accuracy: 0.9787\n",
      "Epoch 98/100\n",
      "91074/91074 [==============================] - 1s 6us/sample - loss: 0.0057 - accuracy: 0.9736 - val_loss: 0.0043 - val_accuracy: 0.9751\n",
      "Epoch 99/100\n",
      "91074/91074 [==============================] - 1s 12us/sample - loss: 0.0055 - accuracy: 0.9741 - val_loss: 0.0043 - val_accuracy: 0.9772\n",
      "Epoch 100/100\n",
      "91074/91074 [==============================] - 1s 11us/sample - loss: 0.0056 - accuracy: 0.9718 - val_loss: 0.0052 - val_accuracy: 0.9777\n"
     ]
    }
   ],
   "source": [
    "kfold_len = 5\n",
    "kfold = KFold(n_splits=kfold_len)\n",
    "\n",
    "nb_epoch = 100\n",
    "batch_size = 512\n",
    "adamax = keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "\n",
    "\n",
    "for idx, (train_index, test_index) in enumerate(kfold.split(X_train)):  # feautres 데이터를 위에서 지정한 kfold 숫자로 분할\n",
    "    print('idx : ', idx)\n",
    "    x_train = X_train[train_index]\n",
    "    x_test = X_train[test_index]\n",
    "    \n",
    "    input_dim = X_train.shape[1]\n",
    "    encoding_dim = 100\n",
    "    input_layer = Input(shape=(input_dim, ))\n",
    "    \n",
    "    encoder = Dense(encoding_dim, activation=\"tanh\")(input_layer)\n",
    "    encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
    "    decoder = Dense(int(encoding_dim / 2), activation='tanh')(encoder)\n",
    "    decoder = Dense(input_dim)(decoder)\n",
    "    \n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "    autoencoder.compile(optimizer=adamax, \n",
    "                        loss=root_mean_squared_error, \n",
    "                        metrics=['accuracy'])\n",
    "    \n",
    "    checkpointer = ModelCheckpoint(filepath=f\"model{idx}.h5\",\n",
    "                                   verbose=0,\n",
    "                                   save_best_only=True)\n",
    "    \n",
    "    tensorboard = TensorBoard(log_dir='./logs',\n",
    "                              histogram_freq=0,\n",
    "                              write_graph=True,\n",
    "                              write_images=True)\n",
    "    \n",
    "    history = autoencoder.fit(x_train, x_train,\n",
    "                        epochs=nb_epoch,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(x_test, x_test),\n",
    "                        verbose=1,\n",
    "                        callbacks=[checkpointer, tensorboard]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "test_list = []\n",
    "\n",
    "for idx in range(kfold_len):\n",
    "    autoencoder = load_model(f'model{idx}.h5', custom_objects = {'root_mean_squared_error' : root_mean_squared_error})\n",
    "    predictions = autoencoder.predict(X_val)\n",
    "    mse = np.mean(np.power(X_val - predictions, 2), axis=1)\n",
    "    error_df = pd.DataFrame({'reconstruction_error': mse})\n",
    "    \n",
    "    means = error_df.describe()['reconstruction_error'].loc['mean']\n",
    "    stds = error_df.describe()['reconstruction_error'].loc['std']\n",
    "        \n",
    "    median = error_df.describe()['reconstruction_error'].loc['50%']\n",
    "    IQR = error_df.describe()['reconstruction_error'].loc['75%'] - error_df.describe()['reconstruction_error'].loc['25%']\n",
    "\n",
    "    threshold = means + 2 * stds\n",
    "    threshold2 = median + 1.5 * IQR\n",
    "    \n",
    "    tests = np.where(mse>=threshold, 1, 0)\n",
    "    test_list.append(tests)\n",
    "    \n",
    "\n",
    "pred = pd.DataFrame(np.array(test_list).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5개의 모델에서 추론한 평균값들이 mse임계값이 일정이상인 열이 6개 이상인 경우 비정상 데이터라고 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    28169\n",
       "1      253\n",
       "2        9\n",
       "3        7\n",
       "4        5\n",
       "5       19\n",
       "Name: sums, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred['sums'] = pred.sum(axis=1)\n",
    "pred['sums'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testset 추론 / 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "test_list = []\n",
    "\n",
    "for idx in range(kfold_len):\n",
    "    autoencoder = load_model(f'model{idx}.h5', custom_objects = {'root_mean_squared_error' : root_mean_squared_error})\n",
    "    predictions = autoencoder.predict(X_test)\n",
    "    mse = np.mean(np.power(X_test - predictions, 2), axis=1)\n",
    "    error_df = pd.DataFrame({'reconstruction_error': mse})\n",
    "    \n",
    "    means = error_df.describe()['reconstruction_error'].loc['mean']\n",
    "    stds = error_df.describe()['reconstruction_error'].loc['std']\n",
    "\n",
    "    median = error_df.describe()['reconstruction_error'].loc['50%']\n",
    "    IQR = error_df.describe()['reconstruction_error'].loc['75%'] - error_df.describe()['reconstruction_error'].loc['25%']\n",
    "\n",
    "    threshold = means + 2 * stds\n",
    "    threshold2 = median + 1.5 * IQR\n",
    "    \n",
    "    tests = np.where(mse>=threshold, 1, 0)\n",
    "    test_list.append(tests)\n",
    "    \n",
    "pred = pd.DataFrame(np.array(test_list).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    141256\n",
       "1       902\n",
       "2        32\n",
       "3        70\n",
       "4        74\n",
       "5       169\n",
       "Name: sums, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred['sums'] = pred.sum(axis=1)\n",
    "pred['sums'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = pred['sums'].apply(lambda x : 1 if (x>=3)&(x<5) else 0)\n",
    "submit = pd.read_csv('ano/sample_submission.csv')\n",
    "submit['Class'] = tests\n",
    "submit.to_csv('ano/ensemble_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단일 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = load_model(f'model_final.h5')\n",
    "predictions = autoencoder.predict(X_test)\n",
    "mse = np.mean(np.power(X_test - predictions, 2), axis=1)\n",
    "    \n",
    "error_df = pd.DataFrame({'reconstruction_error': mse})\n",
    "error_df.describe()\n",
    "\n",
    "means = error_df.describe()['reconstruction_error'].loc['mean']\n",
    "stds = error_df.describe()['reconstruction_error'].loc['std']\n",
    "\n",
    "median = error_df.describe()['reconstruction_error'].loc['50%']\n",
    "IQR = error_df.describe()['reconstruction_error'].loc['75%'] - error_df.describe()['reconstruction_error'].loc['25%']\n",
    "\n",
    "threshold = means + 2 * stds\n",
    "threshold2 = median + 1.5 * IQR\n",
    "\n",
    "tests = np.where(mse>=threshold, 1, 0)\n",
    "\n",
    "submit = pd.read_csv('ano/sample_submission.csv')\n",
    "submit['Class'] = tests\n",
    "submit.to_csv('ano/submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    141337\n",
       "1      1166\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tests).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('ano/sample_submission.csv')\n",
    "submit['Class'] = tests\n",
    "submit.to_csv('ano/single_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Credit Card Fraud Detection using Autoencoders in Keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
